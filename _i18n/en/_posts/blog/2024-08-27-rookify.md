---
layout: post
title:  "Rookify: Migrating from Ceph-Ansible to Rook"
category: tech
author:
- "Rafael te Boekhorst"
avatar:
- "rboekhorst.jpg"
about:
- "rboekhorst.jpg"
---

## Migrating from Ceph-Ansible to Rook with Rookify

To facilitate the transition from Ceph-Ansible to Rook, SCS has almost finished developing a migration tool called [Rookify](https://github.com/SovereignCloudStack/rookify). This tool simplifies and streamlines the migration process, making it easier for users to switch from a Ceph-Ansible deployment to Rook. The tool is now under first technical preview and is being tested.

### Features and Design

#### Statemachine

Rookify is a python package that uses a **state-machine approach** based on the [transitions-library](https://github.com/pytransitions/transitions) to migrate the various resources such as mons, mgrs, osds, mds and anything else, to Rook. Each of these resources has a corresponding [module](https://github.com/SovereignCloudStack/rookify/tree/main/src/rookify/modules) in Rookify, which can be executed  independently or in combination with other modules.

Itâ€™s important to note that most modules have dependencies on other modules and will implicitly run them as needed. For example, the `mgirate-mons`-module needs the `analyze-ceph` module to run first (as indicated by the [REQUIRES variable](https://github.com/SovereignCloudStack/rookify/blob/main/src/rookify/modules/migrate_monitors/main.py)).This is necessary for Rookify to determine the current location of the mons and where they should be migrated to.

Rookify can be configured by editing a comprehensive `config.yml` file, such as the provided [confing.example.yaml](https://github.com/SovereignCloudStack/rookify/blob/main/config.example.yaml). This configuration file specifies various configuration-dependencies (like SSH keys, Kubernetes and Ceph configurations) and allows users to easily decide which modules should be run (see the `migration_modules` section below in `config.yaml`). 

### Pickle support

Rookify optionally (and recommended) supports using a **pickle-file** (see on top below the `general` section in config.example.yaml). [Pickle](https://docs.python.org/3/library/pickle.html) is a model for object serialization that saves the state of progress externally, i.e. which modules have been run and information about the target machine. This means that rookify 'save' its progress:
- if a running migration is for some reason stopped, Rookify can use the pickefile to continue from the saved state
- if a migration is run in parts (e.g. modules are run incrementaly), then the pickelfile allows Rookify to save the state of the cluster, i.e. the migration.

_NOTE_: this means that if the same Rookify installation should be used to migrate more than one cluster, or the one cluster has significantly changed suddenly, the picklefile should be deleted.

#### A simple CLI

New features are currently in development to enhance the existing CLI interface, allowing it to read the pickle file and use Rookify's modules to report the exact state of the migration process. This means, for example, that Rookify will be able to show from where a discontinued or partially failed migration can be continued. 

Currently, Rookify only offers a straightforward CLI interface:

```
usage: Rookify [-h] [--dry-run]

options:
  -h, --help  show this help message and exit
  --dry-run
```

#### Rookify's general workflow: migrating monitors? 

Rookify's main function is to migrate all of Ceph's resources to Rook. Let's take a look at the `migration_modules` section in the `config.yml` file:

```yaml
# config.yml
migration_modules:
- migrate_mons
```

This configuration instructs Rookify to perform the following steps:

1. Preflight Mode: The `migrate_mons` module first runs in a preflight mode, which can also be manually triggered using the `rookify --dry-run` command. During this phase, Rookify runs the preflight methods for the configured modules and their dependent modules. If the migration has already been successfully completed, the module stops here.

2.0 Dependency Check: If the migrate_mons module has not been run before (indicated by an empty pickle file), Rookify checks for dependencies, e.g. other modules that need to be run first. It execute those modules, first in preflight mode and then for real. The state of each module will optionally be saved in the pickle file.

2.1 `ceph-analyze` module: Rookify identifies that the `analyze-ceph` module needs to be run first in any case. The `analyze-ceph` module collects data on the running Ceph resources and the Kubernetes environment with the Rook operator. Note that, like any other module, `ceph-analyze` first runs in preflight mode to check if the state has already been captured in the pickle file. If no state is found, `analyze-ceph` gathers the necessary information.

2.1 Cluster Creation: After successfully running the analyze-ceph` module, Rookify will check for other dependencies, such as the `create-cluster` module. This module creates the cluster map for Rook based on information from `analyze-ceph` and sets up the necessary namespaces in Kubernetes.

3. Migration Execution: Following the successful execution of `analyze_ceph` and `create_cluster`, the `migrate_mons`-module is executed. Rookify shuts down the first running Ceph monitor on the first worker node using `sudo systemctl disable --now ceph-mon.target` and immediately activates the equivalent monitor in Rook by setting its metadata in the clustermap.yaml to true.

4. Monitor Migration: Rookify continues this process for each monitor until all have been migrated to Rook and are running. Optionally, the state can be saved in the pickle file. If, for example, the pickle file contains a finished state of migrate_mons, it will skipp this module and only check if it has indeed bin run sucessfully.

For both managers and monitors, rookify will use the just described approach: it will try to switch of the ceph resource after it has made sure that it can re-create an equivalent in the rook cluster. For OSDs and MDS the migratory algorithm is a bit different.

### Migrating OSDs

Here the "one-by-one"-algorithm described for managers and monitors does not work, because Rook has a container called `prepare_osd` that always tries to find all osds on a path and build all of them at once. Note that there are configuration options that give the impression to handle this, like `use_all_nodes=false` und `use_all_devices=false`. Both variables are set to false per default in the rook deployment of OSISM, nevertheless `prepare_osds` tries to scan and process all osds per node. This means in effect, that a `device is busy`-error will occure as well as a crashloopfeedback. This can be mitigated like so:

1. all OSD daemons have to switched of at once
2. paths of osd devices have to be fed one by to `prepare_osd` to enforce sequential processing
3. wait for each osds on the node to be started before continuing

### Migrating MDSs

The "one-by-one"-algorithm described for managers and monitors does not work here either, because Rook might want to update instances while the migration is in process: This might happen, for example, if one MDSs instance of the ceph-ansible deployment is shutoff and Rook is allowed to rebuild this instance within kubernetes. Then Rook might want to update all MDS instances and will consequently try to switch of all the instances in order to update them: also the ones that are still running under ceph-ansible. Consequently, Rook will not reach these instances and errors will the thrown.

One way to solve this problem, would be to switch of all mds-instances under ceph-ansible and let rook rebuild all of them. That would cause some minimal downtime though, and rookify strives to cause 0 downtime.

That is why rookify currently uses the following approach:
- 2 mds instances (at least one has to be active) will be left under ceph-ansible, all others will be switched off. For example, in case of a total of 3 mds instances, only one mds instance will be switched off.
- now the switched off instances will be given to rook to rebuild them.
- as soons as Rook has finished and the instances are built, the 2 mds instances under ceph-ansible are switched off as well so rook can rebuild and update them as it likes.

## Test run: Give it a try and help with testing process

To get started with Rookify, make sure to checkout the [README.md](https://github.com/SovereignCloudStack/rookify/blob/main/README.md) in the repository.

If you'd like to try to test the current state of Rookify (much apprciated - feel free to report any [issues](https://github.com/SovereignCloudStack/rookify/issues) to Github), you can use the testbed of OSISM. 

### Testbed setup

_NOTE_: The OSISM testbed is intended for testing purposes, which means it may be unstable. If Ceph and K3s cannot be deployed without errors, you may need to wait for a fix or find a workaround to test Rookify. (For example, OSISM also offers a more stable testing setup called "[Cloud in a box](https://osism.tech/docs/guides/other-guides/cloud-in-a-box/)." I will provide more details on this in a future blog post.)

In order to setup the testbed, first consult [OSISM's testbed documentation](https://osism.tech/docs/guides/other-guides/testbed)  to ensure you meet all requirements. If everything is in order, clone the repository and use make ceph to set up a Ceph testbed. This command will automatically pull the necessary Ansible roles, prepare a virtual environment, build the infrastructure with OpenStack, create a manager node, and deploy Ceph on three worker nodes:

```bash
git clone github.com:osism/testbed.git
make ceph
```

Once the infrastructure for Ceph and the testbed has been deployed, log in with make login and deploy K3s as well as a Rook operator:

```bash
make login 
osism apply k3s
osism apply rook-operator
```

If you want to modify any configurations, such as a Rook setting, refer to `/opt/configuration/environments/rook/` and check [OSISM's documentation on Rook](https://osism.tech/docs/guides/configuration-guide/rook) for various settings.

## Rookify Setup/Configuration for OSISM's Testbed

1. **Clone the Rookify Repository**: Start by cloning the Rookify repository, setting it up, and building the Python package in a virtual environment using the Makefile. You can simply run `make` without any arguments to see a list of helper functions that can assist you in setting up and configuring Rookify. The command `make setup` downloads the necessary virtual environment libraries and installs the Rookify package into `.venv/bin/rookify` within the working directory:

```bash
git clone https://github.com/SovereignCloudStack/rookify
cd rookify
make setup
```

_NOTE_: If you encounter an error about the absence of the python-rados library, you can run check-radoslib to check if the library is installed locally. If not, install the package manually. The python-rados library should be version 2.0.0 at the time of writing (check the `README.md` file of Rookify for the most up-to-date documentation). The library could not be integrated within the setup because Ceph currently offers no builds for pip.

2. **Configure Rookify**: Copy `config.example.osism.yml` to `config.yml` and modify the various configuration settings as needed. Rookify will require access to an SSH key (e.g., the `.id_rsa` file in the Terraform directory in the testbed repository), Ceph configuration files (see `/etc/ceph/` on one of the worker nodes), and Kubernetes files (e.g., `~/.kube/config` from the manager node). Check if the Makefile contains any helper functions to assist you: run make in the root of the working directory to see all options that the Makefile offers.

_Important_: Ensure that Rookify can connect to the testbed. To do this, use one of the testbed's built-in VPNs:

```
# you can use sshuttle
make vpn-sshuttle
# Or you can use WireGuard (requires running `make vpn-wireguard-config` first)
make vpn-wireguard
```

3. **Run Rookify**: Finally, run Rookify to test it. Rookify allows the use of `--dry-run` to run modules in preflight mode. Note that Rookify always runs the various modules in preflight mode first before actually executing them. It is safe to run the `example` or `analyze_ceph` modules, as these will not make any real changes.

```yaml
general:
  machine_pickle_file: data.pickle

logging:
  level: INFO # level at which logging should start
  format:
    time: "%Y-%m-%d %H:%M.%S" # other example: "iso"
    renderer: console # or: json

ceph:
  config: ./.ceph/ceph.conf
  keyring: ./.ceph/ceph.client.admin.keyring

# fill in correct path to private key
ssh:
  private_key: /home/USER/.ssh/cloud.private
  hosts:
    testbed-node-0:
      address: 192.168.16.10
      user: dragon
    testbed-node-1:
      address: 192.168.16.11
      user: dragon
    testbed-node-2:
      address: 192.168.16.12
      user: dragon

kubernetes:
  config: ./k8s/config

rook:
  cluster:
    name: osism-ceph
    namespace: rook-ceph
    mds_placement_label: node-role.osism.tech/rook-mds
    mgr_placement_label: node-role.osism.tech/rook-mgr
    mon_placement_label: node-role.osism.tech/rook-mon
    osd_placement_label: node-role.osism.tech/rook-osd
    rgw_placement_label: node-role.osism.tech/rook-rgw
  ceph:
    image: quay.io/ceph/ceph:v18.2.1

migration_modules: # this sets the modules that need to be run. Note that some of the modules require other modules to be run as well, this will happen automatically.
- analyze_ceph
```

If everything is set up correctly, you can run Rookify without any arguments:

```bash
.venv/bin/rookify --dry-run
# or simply
.venv/bin/rookify # the analyze_ceph module is not expected to break anything
```

If all is setup correctly you might see an output similar to this:

```bash
.venv/bin/rookify
2024-09-02 15:21.37 [info     ] Execution started with machine pickle file
2024-09-02 15:21.37 [info     ] AnalyzeCephHandler ran successfully.
```

Note that now there is a `data.pickle` file in root of the working directory and contains data:

```bash
du -sh data.pickle
8.0K	data.pickle
```

At this point we can re-edit the `config.yaml` file to migrate the osds and mds resources:

```
migration_modules:
  - migrate_osds
  - migrate_osd_pools
  - migrate_mds
  - migrate_mds_pools
```

_NOTE_: Some of these are redundant in the sense that their `REQUIRED` variables contain the modules as their dependencies already. For example `migrate_osds` has the following `REQUIRED`-variable: `REQUIRES = ["migrate_mons"]`, and `migrate_mons` has `REQUIRES = ["analyze_ceph", "create_rook_cluster"]`. So it would suffice to add `migrate_osds` to migration_modules. Still, the extra mention of the modules could improve clearity for the reader. In effect rookify will run the modules only once, so it does not hurt to add them in the `config.yaml`.

We can first run rookify with `pre-flight` to check if all is ok and then run it without any arguments. As a consequence you will see how `ceph_analyze` is run, the rook-cluster is created, how the monitors and managers are migrated and then how the osds and mds are migrated as well.
