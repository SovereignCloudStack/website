<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://sovereigncloudstack.github.io/website/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sovereigncloudstack.github.io/website/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-09-30T08:43:09+00:00</updated><id>https://sovereigncloudstack.github.io/website/feed.xml</id><title type="html">Sovereign Cloud Stack</title><subtitle>Sovereign Cloud Stack combines the best of cloud computing in one unified standard. SCS is built, backed, and operated by an active open-source community worldwide. Together we put users in control of their data by enabling cloud operators through a decentralized and federated cloud stack – leveraging true digital sovereignty to foster trust in clouds.</subtitle><entry><title type="html">Final report for funded Sovereign Cloud Stack project (German)</title><link href="https://sovereigncloudstack.github.io/website/release/2025/04/11/final-report/" rel="alternate" type="text/html" title="Final report for funded Sovereign Cloud Stack project (German)" /><published>2025-04-11T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/release/2025/04/11/final-report</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/release/2025/04/11/final-report/"><![CDATA[<h2 id="successful-completion-of-the-funded-sovereign-cloud-stack-scs-project">Successful completion of the funded Sovereign Cloud Stack (SCS) project</h2>

<p>Next to a project sketch, lots of forms and the already public articles
and documentation, a funded project also requires a final report.
The format of it is predefined and parts 1 and 2 are meant for publication.
To that end, they have been handed in at the Technical Information Library
(TIB) of the Leibniz Institute in Hanover on 2025-03-24.</p>

<p>To make these documents more easily accessible to our community, we are
publishing the report here as well, hoping that other projects can
benefit from the gained experience in the technical domain, but particularly
also in the way we have approached the processes and structure of the
funded project.</p>

<h2 id="final-report">Final report</h2>

<p>The report consists of many tables and forms and multiple pieces of text.
We are publishing the following parts:</p>

<ul>
<li><a href="/website/assets/documents/01_Schlussbericht-Teil1-477f22ed580eb1dddd78b04d1a29f3b2c4301eafd14320693e799af00df42e97d23107ba829b1779e9ef1cb5f264d6357230b8dcd3a1755092fffc2b8286d74e.pdf">Part 1: Cover sheet and Short report (2p.)</a></li>
<li><a href="/website/assets/documents/02_Schlussbericht-Teil2-0f27493e1b28ed81f16ea3f8f03d3e84b84de3c2915e99331feb516971ee53eb8688f11bd827003a3e41a7f0240288b1dbcb5ffc5f4a3c105e0a6461cf47c103.pdf">Part 2: Result measurement (20p.)</a></li>
<li><a href="/website/assets/documents/05_Anlage_zur_Liste-Veroeffentlichungen-f180c886c65cd1007c45ca84c0ebe3ed4d5d7d9d987a77ef8648df821a07e471e37e2babfca6937ec2074390273593bffb710b2515282fe3a67f0e7788d9902d.pdf">Appendix to part 2: Publication list</a></li>
</ul>

<p>Please note that the report is available in German language only.</p>

<h2 id="and-on-we-go">And on we go</h2>

<p>The continuation of SCS is based on two pillars.</p>

<p>The first pillar is the evolution of the SCS standards, the development of
compliance tests, certifications and the dissemination and adoption of the
standards. This is driven by a group inside the
<a href="https://osb-alliance.de">OSBA</a>, the <em>Forum SCS-Standards</em>.
It was founded by 14 companies, meanwhile 17, who together are providing the
financial support for the joint standardization work. Further companies and
organizations (private or public) are welcome to join.
The OSBA has created positions for employees to ensure there is meaningful
progress. The standardization governance has been placed inside a
non-profit organization on purpose, ensuring neutrality. This continues to
happen in close collaboration with <a href="https://alasca.cloud/">ALASCA e.V</a>.
More information is available in a <a href="https://www.sovereigncloudstack.org/announcements/osba-forum-scs-standards/">press release on the Forum SCS-Standards</a>.</p>

<p>The other pillar is the continuation of the software engineering work on
the SCS Software (reference implementation). Beyond volunteers, this is primarily
driven by technology companies who have invested into SCS already during the
funded project phase. They are expanding their open source business models
and fund the open source software development through commercial service offers
(such as e.g. subscriptions for maintenance and support but also consulting
or training offers). One visible result of the evolution is the
<a href="https://www.sovereigncloudstack.org/announcements/release8/">Release 8 of the SCS reference implementation</a>.
Thanks to the existing usage of SCS, this is standing on solid ground.
Also, new companies have emerged and are of course welcome.
To deliver on the aspiration to create a large platform for Europe,
a lot more growth of the network is desirable.</p>]]></content><author><name>[&quot;Sovereign Cloud Stack&quot;]</name></author><category term="release" /><summary type="html"><![CDATA[Successful completion of the funded Sovereign Cloud Stack (SCS) project]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/pile-3324375_1280.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/pile-3324375_1280.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">GovStack and SCS collaborate on cloud infrastructure</title><link href="https://sovereigncloudstack.github.io/website/release/2024/12/17/collaboration-scs-govstack/" rel="alternate" type="text/html" title="GovStack and SCS collaborate on cloud infrastructure" /><published>2024-12-17T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/release/2024/12/17/collaboration-scs-govstack</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/release/2024/12/17/collaboration-scs-govstack/"><![CDATA[<h1 id="unlocking-the-power-of-cloud-infrastructure-govstacks-new-building-block-specifications-for-cloud-infrastructure">Unlocking the Power of Cloud Infrastructure: GovStack’s New Building Block Specifications for Cloud Infrastructure</h1>
<h2 id="the-perfect-match-govstack-collaborates-with-sovereign-cloud-stack">The perfect match: GovStack collaborates with Sovereign Cloud Stack</h2>

<p><strong>Berlin, 2024-12-17</strong>: The <a href="https://govstack.global/">GovStack</a> initiative provides guidelines and frameworks supporting countries in their digital transformation by provinding them with building blocks (BB) that help to provide digital services to their citizens. To this end, several working groups publish cross-cutting requirements, building blocks and technical specifications. One of the youngest building block is the <a href="https://govstack.gitbook.io/bb-cloud-infrastructure">Cloud Infrastructure Building Block Specification</a>.</p>

<p>As a non-profit project <a href="https://scs.community/">Sovereign Cloud Stack (SCS)</a> was able to participate in the working group Cloud Infrastructure. The SCS project is funded by the German Federal Ministry of Economics and Climate Action (BMWK) to develop a production-ready, open source cloud infrastructure and container stack, and to provide open standards and operational knowledge. The results of the working group was now <a href="https://www.govstack.global/news/unlocking-the-power-of-cloud-infrastructure-govstacks-new-building-block-specifications-for-cloud-infrastructure/">published</a> in a  first version of recommendations for building digital sovereign cloud infrastructure. With this blueprint, governments and their technical teams have a framework for their own clouds. With this framework, they can build a secure and and reliable cloud using the model that integrates with their digital strategy – a lot of governments tend to use private clouds, but for scalability or as an offering for regional businesses they can use the same technology for public or hybrid clouds.</p>

<p>Both projects share the same mindset on digital sovereignty which made collaboration very effective. Both want to empower their cloud and software users to be sovereign in their decisions on their digital transformation, in their choices of technology, and in their ability to control and design this technology. With the GovStack building block framework, governments can offer their citizens various digital services, based on sovereign cloud infrastructure. This is an important step for each country (including Germany). Many aspects of daily life are digital or digitally supported, and to be able to control their digital space themselves, to shape, and to develop it without unintended lock-in helps countries to strengthen their confidence, to be on par with larger nations.</p>

<p>SCS is completing the picture of GovStack on the practical level – the SCS software covers almost all requirements and recommendations of the specifications (two requirements marked as “recommendation” are not fulfilled, which can be clearly seen <a href="https://testing.govstack.global/requirements/details/Sovereign%20Cloud%20Stack%20(Reference%20Implementation)/reportDetails/66faa70972ad686099693fd3">here</a>) and thus becomes a <a href="https://www.govstack.global/software/">reference implementation</a> of the specs. So, the SCS community and partners are able to support countries to implement their cloud infrastructure – as they want to shape it, in the countries or with trusted hosters. So, SCS is used like it was intended: digitally sovereign, open source, mature cloud infrastructure. For government clouds, for regional OSPOs, as base for a global network, developed by a global, diverse community.</p>

<p>The first collaborations with countries already started in Mauretania, Jordan, Djibuti, Kenia, Somalia. In these countries GovStack supports the governments with their digital transformation, with the opportunity for the countries to host their applications and services in their own sovereign cloud.</p>

<p><strong>About the Sovereign Cloud Stack Project</strong>
SCS has been funded by the German Federal Ministry of Economics and Climate Action (BMWK) since July 2021 and is carried out by the Open Source Business Alliance - Bundesverband für digitale Souveränität e.V.. An international ecosystem of now over 25 companies contributes to the success of the Sovereign Cloud Stack with over 50 software developers. Together, open standards for a modern, federatable open source cloud and container platform are defined and implemented in an open development process using proven open source components. At the same time, operational knowledge and practice is being made transparently available to minimize the difficulty of delivering high-quality and secure cloud services. Already seven providers are using SCS technology productively to operate truly sovereign and GDPR-compliant public cloud offerings. Additional SCS-based cloud infrastructure (public and private clouds) is under construction. SCS is a Lighthouse Project of Gaia-X and provides the development platform for the Gaia-X Federation Services / Cross-Federation Service Components (GXFS/XFSC), and contributes to the German Administrative Cloud of the federal and state governments (Deutsche Verwaltungscloud DVC).</p>

<p><strong>About the Open Source Business Alliance (OSBA) e.V.</strong>
The <a href="https://osb-alliance.de/">Open Source Business Alliance (OSBA)</a> is the association of the open source industry in Germany. It represents over 200 member companies that generate more than EUR 126 billion annually in total. Together with scientific institutions and user organizations, it works to sustainably anchor the central importance of open source software and open standards for a successful digital transformation in the public awareness. In addition, innovations in the field of open source are to be promoted. The goal of the OSBA is to establish open source as a standard in public procure­ment and in research and business development. After all, open source and open standards are compelling foundations for digital sovereignty, innovation capability and security in the digital transformation and thus the answer to one of the greatest challenges of our time.</p>

<p><strong>About GovStack</strong>
GovStack is a global partnership that enables countries and organisations to create cost-effective, efficient and locally tailored digital public services that provide seamless access to critical tools such as health data, identity documents or digital payments. For the use of reusable and interoperable building blocks - such as digital identity, registries, consent, payment and cloud infrastructure - GovStack provides technical specifications, tools and guidance that form the basis for various digital services. GovStack is committed to product neutrality, providing open, customizable frameworks instead of offering ready-made software or promoting specific product solutions over others. By adopting this approach, GovStack ensures governments receive flexible support tailored to every phase of their digital transformation.</p>

<p>Related Links:</p>
<ul>
  <li>GovStack: <a href="https://govstack.global/">https://govstack.global/</a></li>
  <li>Sovereign Cloud Stack: <a href="https://scs.community/">https://scs.community/</a></li>
  <li>Technical Documentation SCS: <a href="https://docs.scs.community/docs">https://docs.scs.community/docs</a></li>
  <li>SCS’s notion of digital sovereignty: <a href="https://the-report.cloud/why-digital-sovereignty-is-more-than-mere-legal-compliance/">https://the-report.cloud/why-digital-sovereignty-is-more-than-mere-legal-compliance/</a></li>
  <li>Cloud Infrastructure Specifications: <a href="https://govstack.gitbook.io/bb-cloud-infrastructure">https://govstack.gitbook.io/bb-cloud-infrastructure</a></li>
</ul>]]></content><author><name>[&quot;Sovereign Cloud Stack&quot;]</name></author><category term="release" /><summary type="html"><![CDATA[Unlocking the Power of Cloud Infrastructure: GovStack’s New Building Block Specifications for Cloud Infrastructure The perfect match: GovStack collaborates with Sovereign Cloud Stack]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/UpdatedVersion.png" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/UpdatedVersion.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Guideline for digital sovereign cloud infrastructure</title><link href="https://sovereigncloudstack.github.io/website/2024/12/04/GovStack/" rel="alternate" type="text/html" title="Guideline for digital sovereign cloud infrastructure" /><published>2024-12-04T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/2024/12/04/GovStack</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/2024/12/04/GovStack/"><![CDATA[<p><img style="width:80%; object-fit: cover;" src="/website/assets/20ec9d-de7f07497840558cbda8e01ddfc75b74ecc577fa29ee3afed223c1db546a1d32f84169ca13649e614d7d767140b7d6b1b3e75569aeb40c23bdb81ad2471f4da1.webp" /></p>

<p>The GovStack initiative provides guidelines and frameworks supporting countries in their digital transformation by provinding them building blocks that help to provide digital services to their citizens. To this end, several working groups publish cross-cutting requirements, building blocks and technical specifications. One of the youngest building block is the <a href="https://govstack.gitbook.io/bb-cloud-infrastructure">Cloud Infrastructure Building Block Specification</a>.</p>

<p>As a non-profit project SCS was able to participate in the working group Cloud Infrastructure. When Martin Wimmer <a href="https://youtu.be/tTfpFwp-zO4">introduced the inititiative</a> at our Summit 2023 I was impressed and so happy to learn that we will be able to contribute our knowledge and expertise to this global approach. It took quite a while to understand how the buildings blocks are structured. But as soon as we got it, we were happy* to write the draft – our recommendations for building digital sovereign cloud infrastructure which is now <a href="https://www.govstack.global/news/unlocking-the-power-of-cloud-infrastructure-govstacks-new-building-block-specifications-for-cloud-infrastructure/">published</a>. With our blueprint, governments and their technical teams have a framework for their own cloud. And the best is, they can build the cloud model they want to integrate in their digital strategy – a lot of governments tend to use private clouds, but for scalability or as an offering for regional businesses they can use the same approach for public or hybrid clouds.</p>

<ul>
  <li>Maybe not everybody was always happy as Kurt wrote the most during night shifts, but the results make all of us happy.</li>
</ul>

<p>For us from SCS, participation in GovStack feels very natural as we share the same mindset. We want cloud or software users to be sovereign in their decisions for their digital transformation, in their choices of technology, and in the ability to control and design this technology. In fact, I really love to be part of this initiative, to support governments, and with this countries, to have a choice, to choose independency on a technological level. With the GovStack building block framework, governments can offer their citizens several digital services, based on sovereign cloud infrastructure. This is an important step for each country (including Germany). Many aspects of daily life are digital or digitally supported, and to be able to control their digital space themselves, to shape, and to develop it without unintended lock-in helps countries to strengthen their confidence, to be on par.</p>

<p>For us it is evident that SCS is completing the picture on the practical level – as SCS covers almost all requirements and recommendations of the specifications. And this is the second aspect of what I love: we are able to support countries to implement their cloud infrastructure – as they want to shape it, in the countries or with trusted hosters. So, SCS is used like it was intended: digitally sovereign, open source, mature cloud infrastructure. For governement clouds, for regional OSPOs, as base for a global network, developed by a global, diverse community. For me, SCS enhances its potential tremendously with GovStack. But, I am a little pre-occupied, maybe…</p>]]></content><author><name>[&quot;Friederike Zelke&quot;]</name></author><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/Infrastructure.png" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/Infrastructure.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Automating SONiC switch provisioning and management with NetBox as a central source</title><link href="https://sovereigncloudstack.github.io/website/tech/2024/11/12/sonic/" rel="alternate" type="text/html" title="Automating SONiC switch provisioning and management with NetBox as a central source" /><published>2024-11-12T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/tech/2024/11/12/sonic</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/tech/2024/11/12/sonic/"><![CDATA[<p>Automating network infrastructure is essential for improving efficiency, scalability, and accuracy, particularly in
large-scale environments. In our setup, we’ve developed a system that automates the provisioning and management of a fleet
of SONiC switches by leveraging tools like Zero-Touch Provisioning (ZTP), Open Network Install Environment (ONIE),
and NetBox as our single source of truth.
This configuration reduces the need for manual setup, minimizes human error, and accelerates deployment by centralizing
control within NetBox, ultimately streamlining device provisioning and configuration across the network.</p>

<h2 id="provisioning">Provisioning</h2>

<p>The architecture for automating the provisioning of SONiC switches relies on several key components:</p>

<ul>
  <li>DHCP Server: Provides initial network configuration for new switches, directing them to ONIE and ZTP for loading the SONiC image and retrieving initial configuration.</li>
  <li>HTTP Server: Hosts SONiC images, ZTP configuration file, and scripts, making them available for download during provisioning.</li>
  <li>NetBox: Acts as the central source of truth, storing device information, configuration template, and scripts that automate ongoing switch management.</li>
</ul>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/sonic/sonic_netbox-6bf94a80c79edb0aefdb5299b9dc5928e0d01873bdecf6fc60efe7b47a9f0ba4f1c5933c1d894d8de727eb9dba6291b00017f63ded69567182ad47eb58953262.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/sonic/sonic_netbox-6bf94a80c79edb0aefdb5299b9dc5928e0d01873bdecf6fc60efe7b47a9f0ba4f1c5933c1d894d8de727eb9dba6291b00017f63ded69567182ad47eb58953262.png" />
  </a>
</figure>

<h3 id="dhcp-server">DHCP server</h3>

<p>The DHCP server plays a critical role in the initial provisioning phase. When a new SONiC switch connects to the network,
the DHCP server assigns it an IP address and provides options for ONIE and ZTP, guiding the switch to download the
SONiC image and its configuration.</p>

<p>The DHCP server can employ various configuration strategies, such as using the vendor-class-identifier to filter devices.
Some of these strategies are detailed in <a href="https://github.com/sonic-net/SONiC/blob/master/doc/ztp/ztp.md">ZTP docs</a> and <a href="https://opencomputeproject.github.io/onie/user-guide/index.html">ONIE docs</a>.</p>

<p>Below is an example of a basic DHCP configuration for a host in the SCS lab environment:</p>
<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>host &lt;host&gt; {
  hardware ethernet &lt;mac-address&gt;;
  server-name "&lt;server-name&gt;";
  option host-name "&lt;host-name&gt;";
  fixed-address &lt;ipv4-address&gt;;
  option default-url "&lt;http-server-address&gt;/sonic-image.bin";
  option bootfile-name "&lt;http-server-address&gt;/ztp.json";
  }
</code></pre></div></div>

<h3 id="http-server">HTTP server</h3>

<p>The HTTP server stores essential files, including the SONiC image and configuration scripts, which ZTP uses to set up
the switch. This server needs to be accessible from the network where the switches are deployed.</p>

<h3 id="netbox">NetBox</h3>

<p>NetBox serves as the backbone of this automated setup, providing a structured and centralized source of truth for device
configurations and management scripts. The configuration for SONiC switches combines a configuration template,
the device’s state as defined in NetBox, and configuration context with static settings such as IP addresses for NTP servers.</p>

<p>The following diagram shows the flow of information used to generate the final SONiC configuration:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Configuration context       NetBox device state
       |                         |
       v                         v
     --------------------------------
    | SONiC configuration template   |
     --------------------------------
                 |
                 v
       ------------------------
      |   SONiC configuration  |
       ------------------------
</code></pre></div></div>

<p>The SONiC configuration is dynamically generated based on the information stored in NetBox and retrieved via its API.
This approach ensures consistency, as the configuration for each switch can be managed centrally and tailored to each
device’s specifications.</p>

<h3 id="onie">ONIE</h3>

<p>ONIE is an open-source boot loader designed to automate the installation of a network operating system (NOS) on bare-metal
network switches. Developed by Cumulus Networks and now widely supported by the Open Compute Project (OCP), ONIE enables
network flexibility by supporting various NOS options, including SONiC, across different hardware platforms.</p>

<p>When a switch with ONIE boots, it enters a discovery mode where it attempts to locate and install a NOS. This process can
be configured through multiple methods, with DHCP being one of the most common. In our DHCP configuration, ONIE retrieves
a designated NOS image URL, allowing it to automatically download and install the appropriate SONiC version as required.</p>

<h3 id="ztp">ZTP</h3>

<p>ZTP is an automated method that streamlines the setup of SONiC network devices, allowing them to be deployed directly
to a site, download configuration files, and begin operation without any manual intervention. This approach significantly
reduces configuration time, minimizes human error, and simplifies scaling.</p>

<p>In our SCS LAB deployment, ZTP enables the initial configuration of network switches.
The ZTP configuration file includes steps to execute essential scripts, retrieve configurations from NetBox (our source of truth),
and validate connectivity. Specifically, the provisioning script within this file pulls the switch’s configuration from
NetBox based on its hostname, ensuring each device receives the appropriate settings, such as interface configurations,
VLANs, BGP configuration and more. Once the configuration is applied, the device automatically reboots, entering its
operational state.</p>

<p>The ZTP configuration file we used is structured as follows:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"ztp"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"01-prerequisites-script"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"plugin"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;http-server-address&gt;/prerequisites.sh"</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"02-provisioning-script"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"plugin"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;http-server-address&gt;/provision.sh"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"ignore-section-data"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
        </span><span class="nl">"args"</span><span class="p">:</span><span class="w"> </span><span class="s2">"--netbox-url &lt;netbox-url&gt; --netbox-token &lt;netbox-token&gt;"</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"03-connectivity-check"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"ping-hosts"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="s2">"&lt;ip-address-that-should-be-reachable&gt;"</span><span class="w">
      </span><span class="p">]</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"reboot-on-success"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>For a detailed example of scripts, visit the related <a href="https://github.com/SovereignCloudStack/hardware-landscape">repository</a>.</p>

<h2 id="management">Management</h2>

<p>In modern network infrastructures, managing switch configurations can become a complex task, especially when dealing
with scalable environments. To streamline network configuration for SONiC devices, we’ve implemented an MVP (Minimum Viable
Product) integration between NetBox and SONiC. This integration leverages NetBox’s data management capabilities with
custom scripts that help automate configuration synchronization for SONiC devices, making it easier to keep network
configurations consistent and compliant.</p>

<p>NetBox has been enhanced to support configuration management for SONiC devices through two custom scripts that automate
configuration tasks. These scripts <code class="language-plaintext highlighter-rouge">SONiC Config Diff</code> and <code class="language-plaintext highlighter-rouge">SONiC Config Sync</code> are designed to align SONiC device
configurations with what’s defined in NetBox. Currently, these scripts are executed manually and offer limited
functionality, but they set the groundwork for more comprehensive network management.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                                 +----------------------+
                                 |         NetBox       |
                                 +----------------------+
                                /|   Sonic Config Diff  |\
                               / |   Sonic Config Sync  | \ 
                              /  +----------------------+  \
                             /              |               \
                            /               |                \
           +-------------------+    +-------------------+     +-------------------+
           |     SONiC SW 1    |    |     SONiC SW 2    | ... |     SONiC SW N    |
           +-------------------+    +-------------------+     +-------------------+
</code></pre></div></div>

<h3 id="sonic-config-diff">SONiC Config Diff</h3>

<p>This script identifies configuration discrepancies between SONiC devices and NetBox. By comparing the running
configuration on SONiC devices with the stored configuration in NetBox, Config Diff highlights differences that could
affect compliance. This script builds on the <code class="language-plaintext highlighter-rouge">netbox-config-diff</code> plugin, extending its capabilities to support SONiC NOS.</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/sonic/netbox_config_compliant-dbbeb66afb59592380b9b4ac41f9110eb4443b1a611e86027ed115694abff321efbca14f2d6e4b2f6757c4b08b1b940468422eba0f382876dc74d1c6020df953.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/sonic/netbox_config_compliant-dbbeb66afb59592380b9b4ac41f9110eb4443b1a611e86027ed115694abff321efbca14f2d6e4b2f6757c4b08b1b940468422eba0f382876dc74d1c6020df953.png" />
  </a>
</figure>

<p>When run, SONiC Config Diff produces a report showing where device settings deviate from the intended configuration,
allowing administrators to easily spot inconsistencies. These results are presented in a visual format, making it easy
to assess compliance at a glance:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/sonic/netbox_config_diff-d5fc31ffea2f68a9fd0296c150cea70e045bf3e9bc070bd0c0ab41f5b145cbf0a1c49e3802c161111487dc259fc1aad557967d3ff5805aa9146a65f319346e51.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/sonic/netbox_config_diff-d5fc31ffea2f68a9fd0296c150cea70e045bf3e9bc070bd0c0ab41f5b145cbf0a1c49e3802c161111487dc259fc1aad557967d3ff5805aa9146a65f319346e51.png" />
  </a>
</figure>

<h3 id="sonic-config-sync">SONiC Config Sync</h3>

<p>While Config Diff identifies differences, SONiC Config Sync enables administrators to apply updates to the SONiC device
based on NetBox configurations. This synchronization process allows NetBox to push missing configuration elements to
SONiC devices, helping bring them up to date with the desired setup. Config Sync is a step toward automated configuration
management, though it only adds configurations and doesn’t support full bidirectional synchronization yet.
Like Config Diff, it can be targeted to specific SONiC devices or run across multiple devices using filters like site,
rack, or device role:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/sonic/netbox_config_sync-45f57252e9689a3884fca082fae8b17792523b49b6dd850a03e0fa813b0dabecf576eee59cb7e477cae316ddb3a3b183165a72aae4f6dd07c7af0b28cbb66d7d.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/sonic/netbox_config_sync-45f57252e9689a3884fca082fae8b17792523b49b6dd850a03e0fa813b0dabecf576eee59cb7e477cae316ddb3a3b183165a72aae4f6dd07c7af0b28cbb66d7d.png" />
  </a>
</figure>

<p>The result is then visualized as follows:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/sonic/netbox_config_sync_done-7b9a64563cd9ef6fc4fd1d5e9ed2ea6b2a6326d14f1f6f987f6f728d5a4e287d916e2a7034fc483efee6381257bb0592549d0611a217d13e5c020113494971e9.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/sonic/netbox_config_sync_done-7b9a64563cd9ef6fc4fd1d5e9ed2ea6b2a6326d14f1f6f987f6f728d5a4e287d916e2a7034fc483efee6381257bb0592549d0611a217d13e5c020113494971e9.png" />
  </a>
</figure>

<p>This blog covers the provisioning and management of SONiC switches,advancing the automation of scalable network environments.
By combining NetBox’s management capabilities with the flexible, open-source SONiC platform, we are laying the foundation
for simplifying administration and reducing operational complexity.</p>

<p>⚙️ Happy automation!</p>]]></content><author><name>[&quot;Matej Feder&quot;]</name></author><category term="tech" /><summary type="html"><![CDATA[Automating network infrastructure is essential for improving efficiency, scalability, and accuracy, particularly in large-scale environments. In our setup, we’ve developed a system that automates the provisioning and management of a fleet of SONiC switches by leveraging tools like Zero-Touch Provisioning (ZTP), Open Network Install Environment (ONIE), and NetBox as our single source of truth. This configuration reduces the need for manual setup, minimizes human error, and accelerates deployment by centralizing control within NetBox, ultimately streamlining device provisioning and configuration across the network.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/default-card.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/default-card.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Rookify: Migrating from Ceph-Ansible to Rook</title><link href="https://sovereigncloudstack.github.io/website/tech/2024/10/30/rookify/" rel="alternate" type="text/html" title="Rookify: Migrating from Ceph-Ansible to Rook" /><published>2024-10-30T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/tech/2024/10/30/rookify</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/tech/2024/10/30/rookify/"><![CDATA[<p>To facilitate the transition from Ceph-Ansible to Rook, SCS has almost finished developing a migration tool called <a href="https://github.com/SovereignCloudStack/rookify">Rookify</a>. This tool simplifies and streamlines the migration process, making it easier for users to switch from a Ceph-Ansible deployment to Rook. The tool is now under first technical preview and is being tested.</p>

<h2 id="features-and-design">Features and Design</h2>

<h3 id="statemachine">Statemachine</h3>

<p>Rookify is a python package that uses a <strong>state-machine</strong> based on the <a href="https://github.com/pytransitions/transitions">transitions-library</a> to migrate the various resources (such as mons, mgrs, osds, mds and anything else) to Rook. Each of these resources has a corresponding <a href="https://github.com/SovereignCloudStack/rookify/tree/main/src/rookify/modules">module</a> in Rookify, which can be executed  independently or in combination with other modules.</p>

<p>It’s important to note that most modules have dependencies on other modules and will implicitly run them as needed. For example, the <code class="language-plaintext highlighter-rouge">mgirate-mons</code> module needs the <code class="language-plaintext highlighter-rouge">analyze-ceph</code> module to run first (as indicated by the <a href="https://github.com/SovereignCloudStack/rookify/blob/main/src/rookify/modules/migrate_monitors/main.py">REQUIRES variable</a>).This is necessary for Rookify to determine the current location of the mons and where they should be migrated to.</p>

<p>Rookify can be configured by editing a comprehensive <code class="language-plaintext highlighter-rouge">config.yaml</code> file, such as the provided <a href="https://github.com/SovereignCloudStack/rookify/blob/main/config.example.yaml">confing.example.yaml</a>. This configuration file specifies various configuration-dependencies (like SSH keys, Kubernetes and Ceph configurations) and allows users to easily decide which modules should be run (see the <code class="language-plaintext highlighter-rouge">migration_modules</code> section below in <code class="language-plaintext highlighter-rouge">config.yaml</code>).</p>

<h3 id="pickle-support">Pickle support</h3>

<p>Rookify optionally (and recommended) supports using a <strong>pickle file</strong> (see on top below the <code class="language-plaintext highlighter-rouge">general</code> section in config.example.yaml). <a href="https://docs.python.org/3/library/pickle.html">Pickle</a> is a model for object serialization that saves the state of progress externally, i.e. which modules have been run and information about the target machine. This means that Rookify can ‘save’ its progress:</p>
<ul>
  <li>if a running migration is for some reason stopped, Rookify can use the pickle file to continue from the saved state.</li>
  <li>if a migration is run in parts (e.g. modules are run incrementally), then the pickle file allows to save the state of the cluster, i.e. the migration.</li>
</ul>

<p>⚠️ <strong>Important:</strong>:
This means that if the same Rookify installation should be used to migrate more than one cluster, or the one cluster has significantly changed suddenly, the pickle file should be deleted manually.</p>

<h3 id="a-simple-cli">A simple CLI</h3>

<p>Currently, Rookify only offers a straightforward CLI interface, which can be displayed by running <code class="language-plaintext highlighter-rouge">rookify</code> with <code class="language-plaintext highlighter-rouge">-h</code> or <code class="language-plaintext highlighter-rouge">--help</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>usage: Rookify [-h] [-d] [-m] [-s]

options:
  -h, --help         show this help message and exit
  -d, --dry-run      Preflight data analysis and migration validation.
  -m, --migrate      Run the migration.
  -s, --show-states  Show states of the modules.
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">-m</code> or <code class="language-plaintext highlighter-rouge">--migrate</code> argument has been added to (really) execute Rookify, while execution without arguments runs in preflight mode, i.e. with <code class="language-plaintext highlighter-rouge">-d</code> or <code class="language-plaintext highlighter-rouge">--dry-run</code>.</p>

<p>The <code class="language-plaintext highlighter-rouge">-s</code> or <code class="language-plaintext highlighter-rouge">--show-states</code> has been added to track the state of progress. The pickle file is read out for this purpose. Each module then reports the known status on <code class="language-plaintext highlighter-rouge">stdout</code>.</p>

<h3 id="rookifys-general-workflow-migrating-monitors">Rookify’s general workflow: migrating monitors?</h3>

<p>Rookify’s main function is to migrate all of Ceph’s resources to Rook. Let’s take a look at the <code class="language-plaintext highlighter-rouge">migration_modules</code> section in the <code class="language-plaintext highlighter-rouge">config.yaml</code> file:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># config.yaml</span>
<span class="na">migration_modules</span><span class="pi">:</span>
<span class="pi">-</span> <span class="s">migrate_mons</span>
</code></pre></div></div>

<p>This configuration instructs Rookify to perform the following steps:</p>

<ol>
  <li>Preflight Mode: The <code class="language-plaintext highlighter-rouge">migrate_mons</code> module first runs in a preflight mode, which can also be manually triggered using the <code class="language-plaintext highlighter-rouge">rookify --dry-run</code> command. During this phase, Rookify runs the preflight methods for the configured modules and their dependent modules. If the migration has already been successfully completed, the module stops here.</li>
  <li>Dependency Check: If the migrate_mons module has not been run before (indicated by an empty pickle file), Rookify checks for dependencies, e.g. other modules that need to be run first. It execute those modules, first in preflight mode and then for real. The state of each module will optionally be saved in the pickle file.
    <ol>
      <li><code class="language-plaintext highlighter-rouge">ceph-analyze</code> module: Rookify identifies that the <code class="language-plaintext highlighter-rouge">analyze-ceph</code> module needs to be run first in any case. The <code class="language-plaintext highlighter-rouge">analyze-ceph</code> module collects data on the running Ceph resources and the Kubernetes environment with the Rook operator. Note that, like any other module, <code class="language-plaintext highlighter-rouge">ceph-analyze</code> first runs in preflight mode to check if the state has already been captured in the pickle file. If no state is found, <code class="language-plaintext highlighter-rouge">analyze-ceph</code> gathers the necessary information.</li>
      <li><code class="language-plaintext highlighter-rouge">k8s_prerequisites_check</code> module: Validation for k8s namespace is done here, as it is required that the cluster namespace has been created manually. Only the CephCluster resource is generated in the next step by <code class="language-plaintext highlighter-rouge">create_rook_cluster</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">create_rook_cluster</code> module: After successfully running the <code class="language-plaintext highlighter-rouge">analyze-ceph</code> and <code class="language-plaintext highlighter-rouge">k8s_prerequisites_check</code> modules, Rookify will check for other dependencies, such as the <code class="language-plaintext highlighter-rouge">create_rook_cluster</code> module. This module creates the <code class="language-plaintext highlighter-rouge">clustermap.yaml</code>  for Rook based on information from <code class="language-plaintext highlighter-rouge">analyze-ceph</code> and  <code class="language-plaintext highlighter-rouge">k8s_prerequisites_check</code>.</li>
    </ol>
  </li>
  <li>Migration Execution: Following the successful execution of <code class="language-plaintext highlighter-rouge">analyze_ceph</code> and <code class="language-plaintext highlighter-rouge">create_cluster</code>, the <code class="language-plaintext highlighter-rouge">migrate_mons</code> module is executed. Rookify shuts down the first running Ceph monitor on the first worker node (using <code class="language-plaintext highlighter-rouge">sudo systemctl disable --now ceph-mon.target</code>) and immediately activates the equivalent monitor in Rook (by setting its metadata in the clustermap.yaml to true).</li>
  <li>Monitor Migration: Rookify continues this process for each monitor until all have been migrated to Rook and are running. Optionally, the state can be saved in the pickle file. If, for example, the pickle file contains a finished state of migrate_mons, it will skip this module and only check if it has indeed bin run successfully.</li>
</ol>

<p>For both managers and monitors, Rookify will use the just described approach: it will try to switch of the ceph resource after it has made sure that it can re-create an equivalent in the Rook cluster. For OSDs and MDS the migratory algorithm is a bit different.</p>

<h3 id="migrating-osds">Migrating OSDs</h3>

<p>Here the “one-by-one”-algorithm described for managers and monitors does not work, because Rook has a container called <code class="language-plaintext highlighter-rouge">rook-ceph-osd-prepare</code> that always tries to find all osds on a path and build all of them at once. Note that there are configuration options that give the impression to handle this, like <code class="language-plaintext highlighter-rouge">useAllNodes=false</code> und <code class="language-plaintext highlighter-rouge">useAllDevices=false</code> (see <a href="https://rook.io/docs/rook/latest-release/CRDs/Cluster/host-cluster/#all-devices">rook docs</a>). Both variables are set to false per default in the Rook deployment of OSISM, nevertheless <code class="language-plaintext highlighter-rouge">rook-ceph-osd-prepare</code> tries to scan and process all osds per node. This means in effect, that a <code class="language-plaintext highlighter-rouge">device is busy</code>-error will occur as well as a crashloop-feedback. This behavior has been mitigated by shutting down all OSD daemons per node:</p>

<ol>
  <li>all OSD daemons per node have to switched of at once</li>
  <li>paths of osd devices have to be fed one by to <code class="language-plaintext highlighter-rouge">rook-ceph-osd-prepare</code> to enforce sequential processing</li>
  <li>wait for each osds on the node to be started before continuing</li>
</ol>

<h3 id="migrating-mdss">Migrating MDSs</h3>

<p>The “one-by-one”-algorithm described for managers and monitors does not work here either, because Rook might want to update instances while the migration is in process: This might happen, for example, if one MDS’s instance of the Ceph-Ansible deployment is shutoff and Rook is allowed to rebuild this instance within Kubernetes. Then Rook might want to update all MDS instances and will consequently try to switch of all the instances in order to update them: also the ones that are still running under Ceph-Ansible. Consequently, Rook will not reach these instances and errors will be thrown.</p>

<p>One way to solve this problem, would be to switch of all mds-instances under Ceph-Ansible and let Rook rebuild all of them. That would cause some minimal downtime though, and Rookify strives to cause 0 downtime.</p>

<p>That is why Rookify currently uses the following approach:</p>
<ol>
  <li>Two mds instances (at least one has to be active) will be left under Ceph-Ansible, all others will be switched off. For example, in case of a total of three mds instances, only one mds instance will be switched off.</li>
  <li>Of the remaining two instances, the first one will now also be shut down and consequently made available for scheduling in Rook, so that a Rook instance starts. The system waits for this start before the last (remaining) instance is shut down and activated in Rook. All further instances will then be mapped in Rook.</li>
</ol>

<h2 id="test-run-give-it-a-try-and-help-with-testing-process">Test run: Give it a try and help with testing process</h2>

<p>To get started with Rookify, make sure to checkout the <a href="https://github.com/SovereignCloudStack/rookify/blob/main/README.md">README.md</a> in the repository.</p>

<p>If you’d like to try to test the current state of Rookify (much appreciated - feel free to report any <a href="https://github.com/SovereignCloudStack/rookify/issues">issues</a> to Github), you can use the testbed of OSISM.</p>

<h3 id="testbed-setup">Testbed setup</h3>

<p>ℹ️ <strong>Info:</strong>
  The OSISM testbed is intended for testing purposes, which means it may be unstable. If Ceph and K3s cannot be deployed without errors, you may need to wait for a fix or find a workaround to test Rookify.</p>

<p>In order to setup the testbed, first consult <a href="https://osism.tech/docs/guides/other-guides/testbed">OSISM’s testbed documentation</a>  to ensure you meet all requirements. If everything is in order, clone the repository and use make ceph to set up a Ceph testbed. This command will automatically pull the necessary Ansible roles, prepare a virtual environment, build the infrastructure with OpenStack, create a manager node, and deploy Ceph on three worker nodes:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone github.com:osism/testbed.git
make ceph
</code></pre></div></div>

<p>Once the infrastructure for Ceph and the testbed has been deployed, log in with make login and deploy K3s as well as a Rook operator:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>make login 
osism apply k3s
osism apply rook-operator
</code></pre></div></div>

<p>If you want to modify any configurations, such as a Rook setting, refer to <code class="language-plaintext highlighter-rouge">/opt/configuration/environments/rook/</code> and check <a href="https://osism.tech/docs/guides/configuration-guide/rook">OSISM’s documentation on Rook</a> for various settings.</p>

<h3 id="rookify-setupconfiguration-for-osisms-testbed">Rookify Setup/Configuration for OSISM’s Testbed</h3>

<h4 id="1-clone-the-rookify-repository">1. Clone the Rookify Repository</h4>

<p>Start by cloning the Rookify repository, setting it up, and building the Python package in a virtual environment using the Makefile. You can simply run <code class="language-plaintext highlighter-rouge">make</code> without any arguments to see a list of helper functions that can assist you in setting up and configuring Rookify. The command <code class="language-plaintext highlighter-rouge">make setup</code> downloads the necessary virtual environment libraries and installs the Rookify package into <code class="language-plaintext highlighter-rouge">.venv/bin/rookify</code> within the working directory:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/SovereignCloudStack/rookify
<span class="nb">cd </span>rookify
make setup
</code></pre></div></div>

<p>ℹ️ <strong>Info:</strong>
  If you encounter an error from the <code class="language-plaintext highlighter-rouge">python-rados</code> library, you can run <code class="language-plaintext highlighter-rouge">make check-radoslib</code> to check if the library is installed locally. If not, install the package manually. The python-rados library should be version 2.0.0 at the time of writing (check the <code class="language-plaintext highlighter-rouge">README.md</code> file of Rookify for the most up-to-date documentation). The library could not be integrated within the setup because Ceph currently offers no builds for pip.</p>

<h4 id="2-configure-rookify">2. Configure Rookify</h4>

<p>Copy <code class="language-plaintext highlighter-rouge">config.example.osism.yaml</code> to <code class="language-plaintext highlighter-rouge">config.yaml</code> and modify the various configuration settings as needed. Rookify will require access to an SSH key (e.g., the <code class="language-plaintext highlighter-rouge">.id_rsa</code> file in the Terraform directory in the testbed repository), Ceph configuration files (see <code class="language-plaintext highlighter-rouge">/etc/ceph/</code> on one of the worker nodes), and Kubernetes files (e.g., <code class="language-plaintext highlighter-rouge">~/.kube/config</code> from the manager node). Check if the Makefile contains any helper functions to assist you: run make in the root of the working directory to see all options that the Makefile offers.</p>

<p>📝 <strong>Note:</strong>
  Ensure that Rookify can connect to the testbed. Refer to <a href="https://osism.tech/docs/guides/other-guides/testbed/#vpn-access">OSISM-documentation</a> about how to setup a VPN connection.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">general</span><span class="pi">:</span>
  <span class="na">machine_pickle_file</span><span class="pi">:</span> <span class="s">data.pickle</span>

<span class="na">logging</span><span class="pi">:</span>
  <span class="na">level</span><span class="pi">:</span> <span class="s">INFO</span> <span class="c1"># level at which logging should start</span>
  <span class="na">format</span><span class="pi">:</span>
    <span class="na">time</span><span class="pi">:</span> <span class="s2">"</span><span class="s">%Y-%m-%d</span><span class="nv"> </span><span class="s">%H:%M.%S"</span> <span class="c1"># other example: "iso"</span>
    <span class="na">renderer</span><span class="pi">:</span> <span class="s">console</span> <span class="c1"># or: json</span>

<span class="na">ceph</span><span class="pi">:</span>
  <span class="na">config</span><span class="pi">:</span> <span class="s">./.ceph/ceph.conf</span>
  <span class="na">keyring</span><span class="pi">:</span> <span class="s">./.ceph/ceph.client.admin.keyring</span>

<span class="c1"># fill in correct path to private key</span>
<span class="na">ssh</span><span class="pi">:</span>
  <span class="na">private_key</span><span class="pi">:</span> <span class="s">/home/USER/.ssh/cloud.private</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="na">testbed-node-0</span><span class="pi">:</span>
      <span class="na">address</span><span class="pi">:</span> <span class="s">192.168.16.10</span>
      <span class="na">user</span><span class="pi">:</span> <span class="s">dragon</span>
    <span class="na">testbed-node-1</span><span class="pi">:</span>
      <span class="na">address</span><span class="pi">:</span> <span class="s">192.168.16.11</span>
      <span class="na">user</span><span class="pi">:</span> <span class="s">dragon</span>
    <span class="na">testbed-node-2</span><span class="pi">:</span>
      <span class="na">address</span><span class="pi">:</span> <span class="s">192.168.16.12</span>
      <span class="na">user</span><span class="pi">:</span> <span class="s">dragon</span>

<span class="na">kubernetes</span><span class="pi">:</span>
  <span class="na">config</span><span class="pi">:</span> <span class="s">./k8s/config</span>

<span class="na">rook</span><span class="pi">:</span>
  <span class="na">cluster</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">osism-ceph</span>
    <span class="na">namespace</span><span class="pi">:</span> <span class="s">rook-ceph</span>
    <span class="na">mds_placement_label</span><span class="pi">:</span> <span class="s">node-role.osism.tech/rook-mds</span>
    <span class="na">mgr_placement_label</span><span class="pi">:</span> <span class="s">node-role.osism.tech/rook-mgr</span>
    <span class="na">mon_placement_label</span><span class="pi">:</span> <span class="s">node-role.osism.tech/rook-mon</span>
    <span class="na">osd_placement_label</span><span class="pi">:</span> <span class="s">node-role.osism.tech/rook-osd</span>
    <span class="na">rgw_placement_label</span><span class="pi">:</span> <span class="s">node-role.osism.tech/rook-rgw</span>
  <span class="na">ceph</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">quay.io/ceph/ceph:v18.2.1</span>

<span class="na">migration_modules</span><span class="pi">:</span> <span class="c1"># this sets the modules that need to be run. Note that some of the modules require other modules to be run as well, this will happen automatically.</span>
<span class="pi">-</span> <span class="s">analyze_ceph</span>
</code></pre></div></div>

<h4 id="3-run-rookify">3. Run Rookify:</h4>

<p>Finally, run Rookify to test it. Rookify allows the use of <code class="language-plaintext highlighter-rouge">--dry-run</code> to run modules in preflight mode. Note that Rookify always checks for a successful run of the various modules in preflight mode before starting the migration.</p>

<p>Additionally it is always safe to run the <code class="language-plaintext highlighter-rouge">analyze_ceph</code> module, as it will not make any real changes.</p>

<p>📝 <strong>Note:</strong>
  By default, Rookify runs in preflight mode. If you execute Rookify without any arguments <code class="language-plaintext highlighter-rouge">--dry-run</code> will be appended.</p>

<p>To be on the secure side, you can now run Rookify in preflight mode. In this case you could also execute it directly, i.e. by adding the argument <code class="language-plaintext highlighter-rouge">--migrate</code> (because the <code class="language-plaintext highlighter-rouge">analyze_ceph</code> module does not break anything):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Preflight mode</span>
.venv/bin/rookify <span class="nt">--dry-run</span>
<span class="c"># Execution mode</span>
.venv/bin/rookify <span class="nt">--migrate</span>
</code></pre></div></div>

<p>⚠️ <strong>Important:</strong>
It is advised to run any module in preflight mode first, to avoid any real changes.</p>

<p>If all is setup correctly you will see an output similar to this:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.venv/bin/rookify <span class="nt">--migrate</span>
2024-09-02 15:21.37 <span class="o">[</span>info     <span class="o">]</span> Execution started with machine pickle file
2024-09-02 15:21.37 <span class="o">[</span>info     <span class="o">]</span> AnalyzeCephHandler ran successfully.
</code></pre></div></div>

<p>Note that now there is a <code class="language-plaintext highlighter-rouge">data.pickle</code> file in the root of your working directory. The file should contain data:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">du</span> <span class="nt">-sh</span> data.pickle
8.0K	data.pickle
</code></pre></div></div>

<p>At this point we can re-edit the <code class="language-plaintext highlighter-rouge">config.yaml</code> file to migrate the osds, mds, managers and radosgateway resources:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>migration_modules:
- analyze_ceph
- create_rook_cluster
- migrate_mons
- migrate_osds
- migrate_osd_pools
- migrate_mds
- migrate_mds_pools
- migrate_mgrs
- migrate_rgws
- migrate_rgw_pools
</code></pre></div></div>

<p>ℹ️ <strong>Info:</strong>
  Some of these are redundant in the sense that their <code class="language-plaintext highlighter-rouge">REQUIRED</code> variables contain the modules as their dependencies already. For example <code class="language-plaintext highlighter-rouge">migrate_osds</code> has the following <code class="language-plaintext highlighter-rouge">REQUIRED</code>-variable: <code class="language-plaintext highlighter-rouge">REQUIRES = ["migrate_mons"]</code>, and <code class="language-plaintext highlighter-rouge">migrate_mons</code> has <code class="language-plaintext highlighter-rouge">REQUIRES = ["analyze_ceph", "create_rook_cluster"]</code>. So it would be fine to skip the first three modules. Still, the extra mention of the modules could improve clarity for the reader. In effect Rookify will run the modules only once, so it does not hurt to add them in the <code class="language-plaintext highlighter-rouge">config.yaml</code>.</p>

<p>We can first run Rookify with in preflight mode ( <code class="language-plaintext highlighter-rouge">--dry-run</code> ) to check if all is ok and then run it with <code class="language-plaintext highlighter-rouge">--migration</code>. Executing Rookify should then give you an output similar to this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.venv/bin/rookify --migration
2024-09-04 08:52.02 [info     ] Execution started with machine pickle file
2024-09-04 08:52.04 [info     ] AnalyzeCephHandler ran successfully.
2024-09-04 08:52.04 [info     ] Validated Ceph to expect cephx auth
2024-09-04 08:52.04 [warning  ] Rook Ceph cluster will be configured without a public network and determine it automatically during runtime
2024-09-04 08:52.04 [info     ] Rook Ceph cluster will be configured without a cluster network
2024-09-04 08:52.11 [warning  ] ceph-mds filesystem 'cephfs' uses an incompatible pool metadata name 'cephfs_metadata' and can not be migrated to Rook automatically
2024-09-04 08:52.16 [info     ] Creating Rook cluster definition
2024-09-04 08:52.16 [info     ] Waiting for Rook cluster created
2024-09-04 08:52.16 [info     ] Migrating ceph-mon daemon 'testbed-node-0'
2024-09-04 08:52.32 [info     ] Disabled ceph-mon daemon 'testbed-node-0'
2024-09-04 08:53.45 [info     ] Quorum of 3 ceph-mon daemons successful
2024-09-04 08:53.45 [info     ] Migrating ceph-mon daemon 'testbed-node-1'
2024-09-04 08:54.07 [info     ] Disabled ceph-mon daemon 'testbed-node-1'
2024-09-04 08:54.44 [info     ] Quorum of 3 ceph-mon daemons successful
2024-09-04 08:54.44 [info     ] Migrating ceph-mon daemon 'testbed-node-2'
2024-09-04 08:55.04 [info     ] Disabled ceph-mon daemon 'testbed-node-2'
2024-09-04 08:55.52 [info     ] Quorum of 3 ceph-mon daemons successful
2024-09-04 08:55.52 [info     ] Migrating ceph-osd host 'testbed-node-0'
2024-09-04 08:55.55 [info     ] Disabled ceph-osd daemon 'testbed-node-0@0'
2024-09-04 08:55.57 [info     ] Disabled ceph-osd daemon 'testbed-node-0@4'
2024-09-04 08:55.57 [info     ] Enabling Rook based ceph-osd node 'testbed-node-0'
2024-09-04 08:57.00 [info     ] Rook based ceph-osd daemon 'testbed-node-0@0' available
2024-09-04 08:57.02 [info     ] Rook based ceph-osd daemon 'testbed-node-0@4' available
2024-09-04 08:57.02 [info     ] Migrating ceph-osd host 'testbed-node-1'
2024-09-04 08:57.05 [info     ] Disabled ceph-osd daemon 'testbed-node-1@1'
2024-09-04 08:57.07 [info     ] Disabled ceph-osd daemon 'testbed-node-1@3'
2024-09-04 08:57.07 [info     ] Enabling Rook based ceph-osd node 'testbed-node-1'
2024-09-04 08:58.46 [info     ] Rook based ceph-osd daemon 'testbed-node-1@1' available
2024-09-04 08:58.46 [info     ] Rook based ceph-osd daemon 'testbed-node-1@3' available
2024-09-04 08:58.46 [info     ] Migrating ceph-osd host 'testbed-node-2'
2024-09-04 08:58.48 [info     ] Disabled ceph-osd daemon 'testbed-node-2@2'
2024-09-04 08:58.50 [info     ] Disabled ceph-osd daemon 'testbed-node-2@5'
2024-09-04 08:58.50 [info     ] Enabling Rook based ceph-osd node 'testbed-node-2'
2024-09-04 09:00.25 [info     ] Rook based ceph-osd daemon 'testbed-node-2@2' available
2024-09-04 09:00.27 [info     ] Rook based ceph-osd daemon 'testbed-node-2@5' available
2024-09-04 09:00.27 [info     ] Migrating ceph-mds daemon at host 'testbed-node-0'
2024-09-04 09:00.27 [info     ] Migrating ceph-mds daemon at host 'testbed-node-1'
2024-09-04 09:00.27 [info     ] Migrating ceph-mds daemon at host 'testbed-node-2'
2024-09-04 09:00.27 [info     ] Migrating ceph-mgr daemon at host'testbed-node-0'
2024-09-04 09:01.03 [info     ] Disabled ceph-mgr daemon 'testbed-node-0' and enabling Rook based daemon
2024-09-04 09:01.20 [info     ] 3 ceph-mgr daemons are available
2024-09-04 09:01.20 [info     ] Migrating ceph-mgr daemon at host'testbed-node-1'
2024-09-04 09:01.51 [info     ] Disabled ceph-mgr daemon 'testbed-node-1' and enabling Rook based daemon
2024-09-04 09:02.09 [info     ] 3 ceph-mgr daemons are available
2024-09-04 09:02.09 [info     ] Migrating ceph-mgr daemon at host'testbed-node-2'
2024-09-04 09:02.41 [info     ] Disabled ceph-mgr daemon 'testbed-node-2' and enabling Rook based daemon
2024-09-04 09:03.00 [info     ] 3 ceph-mgr daemons are available
2024-09-04 09:03.00 [info     ] Migrating ceph-rgw zone 'default'
2024-09-04 09:03.00 [info     ] Migrated ceph-rgw zone 'default'
2024-09-04 09:03.00 [info     ] Migrating ceph-osd pool 'backups'
2024-09-04 09:03.01 [info     ] Migrated ceph-osd pool 'backups'
2024-09-04 09:03.01 [info     ] Migrating ceph-osd pool 'volumes'
2024-09-04 09:03.01 [info     ] Migrated ceph-osd pool 'volumes'
2024-09-04 09:03.01 [info     ] Migrating ceph-osd pool 'images'
2024-09-04 09:03.01 [info     ] Migrated ceph-osd pool 'images'
2024-09-04 09:03.01 [info     ] Migrating ceph-osd pool 'metrics'
2024-09-04 09:03.01 [info     ] Migrated ceph-osd pool 'metrics'
2024-09-04 09:03.01 [info     ] Migrating ceph-osd pool 'vms' 
2024-09-04 09:03.01 [info     ] Migrated ceph-osd pool 'vms'  
2024-09-04 09:03.01 [info     ] Migrating ceph-rgw daemon at host 'testbed-node-2'
2024-09-04 09:04.27 [info     ] Disabled ceph-rgw host 'testbed-node-2'
2024-09-04 09:04.35 [info     ] Rook based RGW daemon for node 'testbed-node-2' available
2024-09-04 09:04.35 [info     ] Migrating ceph-rgw daemon at host 'testbed-node-1'
2024-09-04 09:04.41 [info     ] Disabled ceph-rgw host 'testbed-node-1'
2024-09-04 09:05.09 [info     ] Rook based RGW daemon for node 'testbed-node-1' available
2024-09-04 09:05.09 [info     ] Migrating ceph-rgw daemon at host 'testbed-node-0'
2024-09-04 09:05.13 [info     ] Disabled ceph-rgw host 'testbed-node-0'
2024-09-04 09:05.19 [info     ] Rook based RGW daemon for node 'testbed-node-0' available
</code></pre></div></div>

<p>Wow! You migrated from Ceph-Ansible to Rook! 
Now login into the testbed and check your ceph cluster’s health with <code class="language-plaintext highlighter-rouge">ceph -s</code>. Also use <code class="language-plaintext highlighter-rouge">kubectl</code> to check if all Rook pods are running.</p>]]></content><author><name>[&quot;Rafael te Boekhorst&quot;]</name></author><category term="tech" /><summary type="html"><![CDATA[To facilitate the transition from Ceph-Ansible to Rook, SCS has almost finished developing a migration tool called Rookify. This tool simplifies and streamlines the migration process, making it easier for users to switch from a Ceph-Ansible deployment to Rook. The tool is now under first technical preview and is being tested.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/default-card.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/default-card.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Sovereign Cloud Stack (SCS) sustainable future</title><link href="https://sovereigncloudstack.github.io/website/2024/10/23/osba-forum-scs-standards/" rel="alternate" type="text/html" title="Sovereign Cloud Stack (SCS) sustainable future" /><published>2024-10-23T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/2024/10/23/osba-forum-scs-standards</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/2024/10/23/osba-forum-scs-standards/"><![CDATA[<h2 id="osba-and-members-found-the-forum-scs-standards">OSBA and members found the forum SCS-Standards</h2>

<p><em>Berlin, 2024-10-23: Sovereign Cloud Stack (SCS) provides all
cloud-technological foundations to realize digital sovereignty and
open source strategies and gives users control over their data.
The research project, funded by the German Ministry for
Economic Affairs and Climate Action and carried out by the Open Source Business
Alliance (OSBA), will be concluded as planned on 2024-12-31.
The OSBA and 14 member companies have taken care to ensure a 
sustainable future for the key results and to further advance the
SCS standards.</em></p>

<p>Sovereign Cloud Stack, funded with roughly 13.2 million Euros,
will continue to receive professional development and be available for the cloud
market after the project phase. The OSBA and 14 of its member companies
are founding the forum SCS-standards effective 2025-01-01. This
consortium inside the OSBA takes responsibility for the standards
and certifications and their further evolution in the future.
This also ensures the quality assurance in a sustainable manner.
All users of Sovereign Cloud Stack and the whole ecosystem around
SCS can thus have assurance of relying on a future-proof cloud
technology.</p>

<blockquote>
"SCS embodies quality, transparency and interoperability in the IT industry.
The core topics of standardization and certification are continued in the
newly founding forum SCS-Standards to protect these values." explains
Peter Ganten, chairman of the OSBA.
</blockquote>

<h2 id="14-strong-partners-engage">14 strong partners engage</h2>

<blockquote>
"SCS needs to be advanced even without public subsidies. If we manage to
improve the market conditions and create offerings from various
cloud service providers that are interoperable and federatable thanks
to common standards, this will have beneficial effects on the German and
European cloud economy overall and will lead to long-term success.
This is the reason for our members to invest time and money." comments
Marius Feldmann, COO of Cloud&amp;Heat, chairman of ALASCA e.V. and one of
the two interim chairs of the forum.
</blockquote>

<p>Up to now, 14 companies have collected an annual budget of 257,000 Euros.
Their engagement goes beyond the financial support: They are supporting
the SCS ideas and the common standards. The founding members thus far
are (in alphabetical order):</p>

<ul>
  <li>artcodix GmbH</li>
  <li>B1-Systems GmbH</li>
  <li>Cloud&amp;Heat Technologies GmbH</li>
  <li>Dataport AöR</li>
  <li>dNation, s.r.o.</li>
  <li>OSISM GmbH</li>
  <li>plusserver GmbH</li>
  <li>ScaleUp Technologies GmbH &amp; Co. KG</li>
  <li>secunet Security Networks AG</li>
  <li>STACKXPERTS GmbH</li>
  <li>SysEleven GmbH</li>
  <li>Syself GmbH</li>
  <li>Wavecon GmbH</li>
  <li>Yorizon GmbH</li>
</ul>

<p>The founding members of the forum SCS-Standards are members of the OSBA.
Further companies can support the forum as shaping, consulting or
supporting member. The membership fees depend on the membership level
as well as the company’s financial turnover.</p>

<p>The founding members already started to collaborate intensively, two and
a half months ahead of the official establishment. The founding members
include cloud service providers, data center operators, integrators,
developers, security and training specialists.</p>

<blockquote>
"Our aspiration is to take over the results around the topic SCS standards
from the SCS project on 2025-01-01 and be set up to be fully operational then.
We want to process SCS certifications and award companies in 2025 that are
able to fulfill the demanding requirements from the SCS-Standards." explains
Ralph Dehner of B1 Systems, co-chair of the forum.
</blockquote>

<h2 id="collaboration-on-standardization-strengthens-the-market">Collaboration on Standardization strengthens the market</h2>

<blockquote>
"The non-profit approach, the openness of the standards and the fair
access for all market players is strongly anchored by founding the
forum SCS-Standards within the OSBA by the engaged founding members.
This is a substantial contribution to digital sovereignty in Germany
and Europe." comments Peter Ganten, chairman of the OSBA, and expresses
his gratitude to the involved companies.
</blockquote>

<p>The forum SCS-Standards is open for further members.
Interested parties should contact
<a href="mailto:forum-scs-standards@osb-alliance.com">forum-scs-standards@osb-alliance.com</a>.</p>

<h3 id="references">References:</h3>

<ul>
  <li><a href="https://scs.community/">Sovereign Cloud Stack</a></li>
  <li><a href="https://docs.scs.community/docs">Technical documentation SCS</a></li>
  <li><a href="https://github.com/SovereignCloudStack">SCS repositories</a></li>
  <li>SCS classification of digital sovereignty
    <ul>
      <li><a href="https://the-report.cloud/why-digital-sovereignty-is-%20more-than-mere-legal-compliance">Why Digital Sovereignty is more than mere Legal Compliance</a></li>
      <li><a href="https://link.springer.com/epdf/10.1007/s11623-022-1669-5?sharing_token=ie7xTVzv_afod07w5Y2lJfe4RwlQNchNByi7wbcMAY4yFyxh9Qw2iCtygUYjun7MI5leBYqiHZBlIeTPv8Sm1Wv8c1dEUf6ebSwnRfo99_nAYh2FgwUyIHjFyZFWv_EIOEIetr2eBSiAPrI68ptBgKxMVkNlS4udZRAhx1X-WB8">Digitale Souveränität und Initiativen zur ihrer Verwirklichung (GERMAN)</a></li>
    </ul>
  </li>
</ul>

<h3 id="about-the-sovereign-cloud-stack-project">About the Sovereign Cloud Stack project</h3>

<p>SCS is being funded by the Ministry for Economic Affairs and Climate Action
(BMWK) since July 2021 and is run by the Open Source Business Alliance e.V.
A growing international ecosystem of meanwhile more than 25 companies
contributes to its success with more than 50 software developers,
collaborating with thousands of developers in the upstream communities
around the OpenInfra Foundation, Cloud Native Computing Foundation and
others. There also exists a partnership with ALASCA e.V.. An open development
process is used to jointly define open standards for a modern, federatable
open source cloud and container platform. Proven open source components
are used to implement them in production-grade software. In addition,
operation knowledge and processes are made transparent to overcome the
challenges of providing a highly reliable and secure cloud service to
a high degree. The SCS technology is already used by six public cloud
providers in production to provide of truly sovereign and GDPR compliant
cloud offerings. More setups – both public and private clouds – are
built. SCS also contributes to Gaia-X and delivers the development platform
for the Gaia-X Federation Services / Cross-Federation Service Components
(GXFS/XFSC).</p>

<h3 id="about-the-open-source-business-alliance--federal-alliance-for-digital-sovereignty-ev">About the Open Source Business Alliance – Federal Alliance for Digital Sovereignty e.V.</h3>

<p>The Open Source Business Alliance (OSBA) is the association of the Open
Source Industry in Germany. It represents over 200 member companies, who
together have a turnover of above 126 billion Euros. Together with
scientific institutes and user organizations, it advocates for the
public awareness of the key importance of Open Source Software and Open
Standards for a successful digital transformation. It supports innovation
for Open Source. The goal of the OSB Alliance is to establish Open Source
as a standard policy in public procurement and in publicly supported
research and economic development projects. Open Source and Open Standards
represent the inevitable foundation for digital sovereignty, freedom to
innovate and security in the digital transformation and thus the answer
to one of the most significant challenges of our time.</p>

<p>Contact:</p>

<p>Open Source Business Alliance – Bundesverband für digitale Souveränität e.V.
Pariser Platz 6a
10117 Berlin</p>

<p>Lisa Reisch
Press officer of the OSBA, Tel.: +49 (30) 300 149 3377
<a href="mailto:presse@osb-alliance.com">email</a>
<a href="https://www.osb-alliance.com/">Internet</a></p>]]></content><author><name>[&quot;Lisa Reisch&quot;]</name></author><summary type="html"><![CDATA[OSBA and members found the forum SCS-Standards]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/forumscs-1-474x324.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/forumscs-1-474x324.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Demystifying Gaia-X Credentials</title><link href="https://sovereigncloudstack.github.io/website/2024/10/15/demystifying-gaia-x-credentials/" rel="alternate" type="text/html" title="Demystifying Gaia-X Credentials" /><published>2024-10-15T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/2024/10/15/demystifying-gaia-x-credentials</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/2024/10/15/demystifying-gaia-x-credentials/"><![CDATA[<p>This blog post will introduce the requirements and detailed technical process of creating and obtaining Verifiable Credentials (VC for short) for Gaia-X and using the <a href="https://gaia-x.eu/gxdch/">Gaia-X Digital Clearing House (GXDCH)</a> to assert compliance.</p>

<p>We recommend reading the Gaia-X’s own blog post on <a href="https://gaia-x.eu/news-press/gaia-x-and-verifiable-credentials-presentations/">Gaia-X and Verifiable Credentials / Presentations</a> to get familiar with the idea and concepts behind <strong>Verifiable Credentials</strong> and <strong>Verifiable Presentations</strong>.</p>

<p>The process described in this blog post is for the most part an example realization of <a href="https://docs.gaia-x.eu/policy-rules-committee/policy-rules-conformity-document/23.10/Process/">how to become a Gaia-X conformant user</a> as documented by Gaia-X, further extended by the process of publishing Gaia-X compliant VCs for cloud service offerings as well.</p>

<p>This blog post will refer to the latest stable Gaia-X release at the time of writing (which is 22.10 - codenamed “Tagus”) and the corresponding <a href="https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/">Gaia-X Trust Framework 22.10 release</a>.
Details of the process described here might change in future Gaia-X releases. Please consult the corresponding documentation.</p>

<h2 id="terminology">Terminology</h2>

<p>It is important to clarify some terms and concepts used throughout this blog post before moving on.</p>

<h4 id="gaia-x-ontology">Gaia-X Ontology</h4>

<p>The <a href="https://gitlab.com/gaia-x/technical-committee/service-characteristics-working-group/service-characteristics">Gaia-X Ontology</a> defines a set of classes and their properties used to describe Gaia-X entites.
The latest version of the Gaia-X Ontology is published in the <a href="https://registry.lab.gaia-x.eu/docs/#menu">Gaia-X Registry</a> of the GXDCH.</p>

<h4 id="gaia-x-credentials--verifiable-credentials">Gaia-X Credentials / Verifiable Credentials</h4>

<p>Gaia-X regulates descriptions of <strong>Cloud Service Providers (CSPs)</strong> and their services as <strong>Gaia-X Credentials</strong>. A Gaia-X Credential is a set of crypographically signed claims about one or more Gaia-X entities. A Gaia-X entity is a <em>Participant</em> (including Service Consumer and Service Provider), a <em>Service Offering</em> and/or a <em>Resource</em>, a Service Offering is aggregated of.</p>

<p>The term <strong>Gaia-X Credential</strong> refers to a <strong>Verifiable Credential</strong> in the context of Gaia-X.
It is based on the <a href="https://www.w3.org/TR/vc-data-model/">W3C Verifiable Credentials Data Model v1.1</a> but follows some more specialized restrictions specific to Gaia-X.
Those are described in the <a href="https://docs.gaia-x.eu/technical-committee/identity-credential-access-management/22.10/credential_format/">Credential format documentation</a>.
Notable key aspects are:</p>

<ul>
  <li>The serialization format is <a href="https://json-ld.org/">JSON-LD</a>.</li>
  <li>The verification method (= public key to verify proof) type is <a href="https://datatracker.ietf.org/doc/html/rfc7517">JSON Web Key</a> entailing compacted <a href="https://w3c-ccg.github.io/lds-jws2020/">JSON Web Signature</a> as embedded proof value.</li>
  <li>Claims are expressed as <a href="https://www.w3.org/TR/rdf11-concepts/">Resource Description Framwork (RDF)</a> triples and <a href="https://docs.gaia-x.eu/technical-committee/identity-credential-access-management/22.10/credential_format/#namespace-bindings-and-contexts">MUST use</a> the Gaia-X Ontology in their context.</li>
  <li>Any <code class="language-plaintext highlighter-rouge">id</code> fields of Verifiable Credentials (including their <code class="language-plaintext highlighter-rouge">credentialSubject.id</code>) <a href="https://docs.gaia-x.eu/technical-committee/identity-credential-access-management/22.10/credential_format/#identifiers">MUST be unique</a>.</li>
</ul>

<p>In this blog post, the term Verifiable Credential is used interchangeably with Gaia-X Credential.</p>

<p>At the time of writing, the old term <strong>Self-Description</strong> is still encountered in a lot of resources concerning Gaia-X.
The term Self-Description was replaced by <strong>Gaia-X Credential</strong> a long time ago, but not all of the <a href="https://docs.gaia-x.eu/">Gaia-X documents</a> are updated accordingly yet.
This blog post uses the new term Gaia-X Credential.</p>

<h4 id="verifiable-presentations">Verifiable Presentations</h4>

<p>Claims about a Gaia-X entity may be distributed across multiple Gaia-X Credentials.
Furthermore, Gaia-X Credentials may contain references to other Gaia-X Credentials.
Gaia-X uses the concept of <strong>Verifiable Presentations</strong> following the <a href="https://www.w3.org/TR/vc-data-model/">W3C Verifiable Credentials Data Model</a> to combine all claims about a Gaia-X entity.</p>

<p>A <strong>Verifiable Presentation</strong> representing a Cloud Service Provider (CSP) and their offerings as a form of self-description is usually submitted to the Compliance Service of the GXDCH, resulting in a Gaia-X Credential that attests the compliance.</p>

<h2 id="desired-goal">Desired Goal</h2>

<p>This blog post will be based on the following use case:</p>

<p>A Cloud Service Provider (CSP) wants to publish Gaia-X Credentials containing proven claims about their identity and cloud service offerings conforming to the Gaia-X Framework and attest Gaia-X compliance.
To achieve this, the CSP assembles Verifiable Presentations that contain several Gaia-X Credentials which in total will both represent and prove the CSP’s identity as well as their offerings as a form of self-description.
The Gaia-X Credentials, representing individual claims, are individually issued and signed either by the CSP itself or an authorized third-party (such as the GXDCH) depending on their subjects.
Finally, the Gaia-X Compliance Service of the GXDCH will verify the Verifiable Presentation’s contents (including the individual Verifiable Credentials and their proofs) and issue a Verifiable Credential attesting the compliance of the Verifiable Presentation as a whole.</p>

<p>This process is summarized in the following figure, taking a Verifiable Presentation for a service offering as an example:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/gx-credentials/gx-verifiable-presentation-f4f73257af24ef9113407db3588ec75cc372220a5dd0094b9a7242d834b7fdd986b6f7a0c32adfb5034c68cb1850650651133718f00c8e197cad9cb26bda0173.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-verifiable-presentation-f4f73257af24ef9113407db3588ec75cc372220a5dd0094b9a7242d834b7fdd986b6f7a0c32adfb5034c68cb1850650651133718f00c8e197cad9cb26bda0173.png" />
  </a>
</figure>

<p>Most Gaia-X Credentials included in a Verifiable Presentation are self-signed by the CSP.
One exception to this is the Gaia-X Credential for the Legal Registration Number (LRN) of the CSP which instead is signed by the GXDCH involving a dedicated Gaia-X Notarization Service API for verifying the LRN and attesting its validity.</p>

<p>The specific set of Gaia-X Credentials a CSP includes in each of their Verifiable Presentations may vary depending on what kind of proven claims the CSP wants to present therein.
For the purpose of this blog post we will focus on a very common and basic use case of Verifiable Presentations containing the following Gaia-X Credentials:</p>

<ol>
  <li>The <strong>Legal Registration Number</strong> (LRN) belonging to the CSP.</li>
  <li>The <strong>Legal Participant</strong> credential representing the CSP as a legal person identified by the LRN.</li>
  <li>The signed Gaia-X <strong>Terms &amp; Conditions</strong> which the CSP pledges to adhere to.</li>
  <li>The <strong>Service Offering</strong> credential representing the CSP’s digital service available for order.</li>
</ol>

<p>We will first create a Verifiable Presentation containing credentials no. 1 through 3 to represent a minimal set representing the CSP identity.
Following this, we will add credential no. 4 to create another Verifiable Presentation that covers the service offerings as well.</p>

<h2 id="required-identity-assets-for-credential-creation">Required Identity Assets for Credential Creation</h2>

<p>In order to successfully create Verifiable Credentials for the Gaia-X Compliance as illustrated above, the following assets are necessary on the CSP side:</p>

<ol>
  <li>A DNS record and web server for hosting the Gaia-X related identity assets</li>
  <li>A public/private key pair compatible with JSON Web Signatures (JWS) and a corresponding X.509 certificate chain containing the public key. GXDCH expected <a href="https://en.wikipedia.org/wiki/EIDAS">EIDAS</a> or <a href="https://en.wikipedia.org/wiki/Extended_Validation_Certificate">evSSL</a> certificate as trust anchor of x.509 certificate chain. Deployment endpoints of GXDCH accept <a href="https://letsencrypt.org/">Let’s Encrypt certificates</a> as trust anchor, too.  You can verify compliance of your x.509 certificate chain via <code class="language-plaintext highlighter-rouge">TrustAnchor/TrustAnchorController_findTrustAnchor</code> endpoint of GXDCH Registry Service.
    <ul>
      <li>the X.509 certificate chain needs to be hosted publicly</li>
    </ul>
  </li>
  <li>A <a href="https://www.w3.org/TR/did-core/">Decentralized Identifier (DID)</a> and a DID document associated with the DID. DID and DID document are linked via <a href="https://www.w3.org/TR/did-core/#methods">DID method</a>. This blog post uses <a href="https://w3c-ccg.github.io/did-method-web/">did:web method</a>. However, Gaia-X does not make any limitations with respect to used DID methods.
    <ul>
      <li>the DID document is a JSON file that needs to be hosted publicly at <code class="language-plaintext highlighter-rouge">&lt;DNS record&gt;/.well-known/did.json</code></li>
    </ul>
  </li>
</ol>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/gx-credentials/gx-credentials-creation-454f6f20879740a97b8bd5f0ad567a7367e5a3514d54e7da47d1bbe67db373faca1ea8308b2b3a4d5bcf93ec5208db3c680aaee3469a6226cc9b4411deb9ed34.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-credentials-creation-454f6f20879740a97b8bd5f0ad567a7367e5a3514d54e7da47d1bbe67db373faca1ea8308b2b3a4d5bcf93ec5208db3c680aaee3469a6226cc9b4411deb9ed34.png" />
  </a>
</figure>

<p>The relations between those parts are as follows:</p>

<ul>
  <li>the private key of the public/private key pair will be used by the CSP to locally sign Gaia-X Credentials</li>
  <li>the public key of the public/private key pair will be used by other parties to verify the signature of CSP-signed Gaia-X Credentials</li>
  <li>the public key is hosted by the CSP as part of the DID document and certificate chain files</li>
  <li>the DID document contains both the public key for signature validation as well as a URL reference to the full X.509 certificate chain for the public key</li>
  <li>the path to the public key is encoded in the “proof” section of the Gaia-X Credential. This reference points to a specific section in DID document, which describes the public key.</li>
</ul>

<p>Using the DID document and the certificate chain including the public key hosted by the CSP (acting as provider), a consumer will be able to verify the signature of a Gaia-X Credential issued by the CSP by resolving the DID reference and retrieving the certificate:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/gx-credentials/gx-credentials-verification-93fa8e888eda7f48af7b84d037e088c572894c3eb49fade292e94a399169281d7afcd5d4cd20b0fc3f44ec126a160a92fc62cce4cb56a7e6a704b87401fa8705.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-credentials-verification-93fa8e888eda7f48af7b84d037e088c572894c3eb49fade292e94a399169281d7afcd5d4cd20b0fc3f44ec126a160a92fc62cce4cb56a7e6a704b87401fa8705.png" />
  </a>
</figure>

<h2 id="creating-a-compliant-verifiable-presentation-step-by-step">Creating a compliant Verifiable Presentation step-by-step</h2>

<p>The following sections of this blog post will guide through the individual steps of creating the necessary identity assets, basic Gaia-X Credentials and finally the first Verifiable Presentation about the CSP identity.
At the end, the process of generating a credential about service offerings and creating a second Verifiable Presentation incorporating it will be explained as well.</p>

<p>The steps will require an up and running web server with a registered DNS record where files can be served from.
This server and its DNS record will be referred to as <code class="language-plaintext highlighter-rouge">mydomain.com</code> for the explanations below.</p>

<h3 id="step-1-preparing-the-publicprivate-key-pair">Step 1: Preparing the public/private key pair</h3>

<p>For the purpose of this blog post we will be using Let’s Encrypt for generating the public/private key pair and X.509 certificate chain.
This makes the process very quick and easy and we can focus on the more intericate parts of the Gaia-X-specific workflow.
Note that for the Gaia-X production release, a X.509 certificate chain originating from one of the <a href="https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/trust_anchors/#list-of-defined-trust-anchors">Gaia-X Trust Anchors</a> will be required, which excludes Let’s Encrypt as it does not offer EV SSL certificates.
For testing this process, we can use the “v1-staging” Gaia-X API intended for development and testing purposes, which is a bit more lenient in this regard and will accept Let’s Encrypt certificates.</p>

<p>Please refer to the official <a href="https://certbot.eff.org/instructions">Certbot ACME client documentation</a> on how to get started with Let’s Encrypt on a web server.
Using Certbot to perform the key generation and certificate issuance results in the following files:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">privkey.pem</code>
    <ul>
      <li>the private key of your public/private key pair</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">cert.pem</code>
    <ul>
      <li>your resulting certificate (a leaf certificate), includes the public key of your key pair</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">chain.pem</code>
    <ul>
      <li>Let’s Encrypt’s intermediate certificate</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">fullchain.pem</code>
    <ul>
      <li>certificate chain, simply a combination of <code class="language-plaintext highlighter-rouge">cert.pem</code> and <code class="language-plaintext highlighter-rouge">chain.pem</code></li>
    </ul>
  </li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">chain.pem</code> certificate is only an intermediate certificate.
It references <a href="https://letsencrypt.org/certificates/#root-cas">Let’s Encrypt’s root certificate</a> (ISRG Root X1/X2) but the <code class="language-plaintext highlighter-rouge">fullchain.pem</code> does not include it.
Since the Gaia-X Compliance API will require the full certificate chain (including the root certificate) to be present for validation later on, the certificate chain needs to be adjusted.</p>

<p>This can be done by manually building the full certificate chain:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># start building the certificate chain from the leaf and intermediate certificates</span>
<span class="nb">cat </span>cert.pem chain.pem | <span class="nb">tee</span> /srv/.well-known/x509CertificateChain.pem

<span class="c"># retrieve and append the ISRG Root X1 certificate</span>
curl <span class="nt">-s</span> <span class="se">\</span>
    https://crt.sh/?d<span class="o">=</span>96BCEC06264976F37460779ACF28C5A7CFE8A3C0AAE11A8FFCEE05C0BDDF08C6 <span class="se">\</span>
    | <span class="nb">tee</span> <span class="nt">-a</span> /srv/.well-known/x509CertificateChain.pem
</code></pre></div></div>
<p>(this example assumes <code class="language-plaintext highlighter-rouge">/srv/</code> is the path your web server serves files from)</p>

<p>The <code class="language-plaintext highlighter-rouge">crt.sh</code> URL to the ISRG Root X1 certificate in this example was retrieved from <a href="https://wiki.mozilla.org/CA/Included_Certificates">Mozilla’s index of included CA certificates</a>.</p>

<p>Host the <code class="language-plaintext highlighter-rouge">x509CertificateChain.pem</code> on the web server accordingly.
It will be required for the next step.</p>

<p>If the web server is not configured for HTTPS yet, these key files may be used for its TLS configuration as well.</p>

<h3 id="step-2-creating-the-decentralized-identifier-did-document">Step 2: Creating the Decentralized Identifier (DID) document</h3>

<p>A central element of the whole process of verifying Verifiable Credentials is the Decentralized Identifier (DID for short) of the corresponding signee. Gaia-X uses <a href="https://www.w3.org/TR/did-core/">W3C’s DID standard</a> for those.
A DID document is linked to the private key used to sign Verifiable Credentials and contains verification assets (e.g. public key) for verification as illustrated in the introductory section.</p>

<p>The DID document must be publicly accessible and is usually referenced in Verifiable Credentials using the <a href="https://www.w3.org/TR/did-core/#a-simple-example">DID-specific URI scheme</a>, for example: <code class="language-plaintext highlighter-rouge">did:web:my-domain.com</code>.
The <a href="https://w3c-ccg.github.io/did-method-web/"><code class="language-plaintext highlighter-rouge">did:web</code> method</a> specified in the example will resolve to <code class="language-plaintext highlighter-rouge">https://my-domain.com/.well-known/did.json</code>.</p>

<p>Some notes about the <code class="language-plaintext highlighter-rouge">did:web</code> method used here:</p>

<ul>
  <li>HTTPS (TLS) is mandatory for the <code class="language-plaintext highlighter-rouge">did:web</code> method and is automatically chosen.</li>
  <li>When no path segments are specified after the domain name (using colon delimiters), this method defaults to <code class="language-plaintext highlighter-rouge">.well-known/</code> on the web server.</li>
  <li>The resulting URL will be used to look up <code class="language-plaintext highlighter-rouge">did.json</code> on the web server, this filename is hardcoded.</li>
</ul>

<p>To generate the DID document, the <a href="https://github.com/SovereignCloudStack/scs-did-creator/">SCS DID creator</a> can be utilized.
Specify the URL to <code class="language-plaintext highlighter-rouge">x509CertificateChain.pem</code> certificate chain file as input for the verification methods.</p>

<p>Make sure to double check that you don’t accidentally reference your private key in the DID document!
In the context of your key pair, only the public key and a reference to the X.509 certificate chain should be part of this document.</p>

<p>If done correctly, the DID document should contain our public key and the URL of the <code class="language-plaintext highlighter-rouge">x509CertificateChain.pem</code> file:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="err">...</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:mydomain.com"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"verificationMethod"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:mydomain.com#JWK2020-RSA"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"JsonWebKey2020"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"publicKeyJwk"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"n"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;public key here&gt;"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"x5u"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/x509CertificateChain.pem"</span><span class="w">
        </span><span class="err">...</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="err">...</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="err">...</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>(contents truncated for readability)</p>

<p>This file is to be placed as <code class="language-plaintext highlighter-rouge">/.well-known/did.json</code> on the web server, e.g. <code class="language-plaintext highlighter-rouge">mydomain.com/.well-known/did.json</code>.
As a result it will be accessible using the DID reference <code class="language-plaintext highlighter-rouge">did:web:mydomain.com</code> which we will be using when creating Gaia-X Credentials in the following steps.</p>

<p><strong>Important:</strong> Each <code class="language-plaintext highlighter-rouge">verificationMethod</code> entry in the DID document receives a unique <code class="language-plaintext highlighter-rouge">id</code> field. When creating Verifiable Credentials referencing the DID document, their <code class="language-plaintext highlighter-rouge">proof.verificationMethod</code> value must exactly match one of the <code class="language-plaintext highlighter-rouge">id</code>s within <code class="language-plaintext highlighter-rouge">verificationMethod</code> of the DID document! This includes the <code class="language-plaintext highlighter-rouge">#</code>-prefixed appendix (<code class="language-plaintext highlighter-rouge">did:web:mydomain.com#JWK2020-RSA</code> in this example).</p>

<h3 id="step-3-gaia-x-credential-for-legal-registration-number-lrn">Step 3: Gaia-X Credential for Legal Registration Number (LRN)</h3>

<p>To be acknowledged as a proper participant in the Gaia-X Trust Framework we need to legally identify ourselves as a <a href="https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/participant/#legal-person">legal person</a> that represents our entity (e.g. company).
For this purpose we need a Gaia-X Credential for our Legal Registration Number (LRN) as a requirement for our Participant Gaia-X Credential later on.</p>

<p>As mentioned in the introductory sections, the LRN Gaia-X Credential takes a special position in this context as it is one of the few Credentials that is not signed by the CSP itself.
Instead, the trust anchor lies at the GXDCH which verifies the LRN and attests its validity.
The Clearing House has a dedicated API for this: the Notarization API.
You can use the <a href="https://wizard.lab.gaia-x.eu/legalRegistrationNumber">Gaia-X Wizard</a> for creating the Gaia-X Credentials or use the Notarization API directly.</p>

<p>There is a notable quirk about the process here that needs some explanation before we go on.
When requesting a LRN Gaia-X Credential a <strong>Verifiable Credential identifier</strong> must be provided.
This corresponds to “Verifiable Credential ID” in the Gaia-X Wizard or the “vcid” path parameter of the API.
In addition to that a <strong>credential subject identifier</strong> will need to be specified as well.
This corresponds to “Credential subject ID” in the Gaia-X Wizard or the “id” request body field when using the API.
Below is a visualization of this structure:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/gx-credentials/gx-lrn-credential-structure-595dd7f034dfdfbd79d36e0b1af5c6c4c38b5ad474066eda64d2432a1536e9710b1c150e1aa19fc1f0f22ff320efc92cef57b7e682a7e819bed4f370f1e2e3ce.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-lrn-credential-structure-595dd7f034dfdfbd79d36e0b1af5c6c4c38b5ad474066eda64d2432a1536e9710b1c150e1aa19fc1f0f22ff320efc92cef57b7e682a7e819bed4f370f1e2e3ce.png" />
  </a>
</figure>

<p>Instead of using a identifier that is only valid locally within a Verifiable Presentation (more on that later) we can opt for both identifiers to contain the URL to hosted instance of our LRN Gaia-X Credential.
For the purpose of demonstration, we will do that next but keep in mind that this is optional for Verifiable Credentials as the <a href="https://docs.gaia-x.eu/technical-committee/identity-credential-access-management/22.10/credential_format/#identifiers">Gaia-X documentation on identifiers</a> states:</p>

<blockquote>
  <p>It is up to the issuer to decide if the @id is a resolvable URI or not.</p>
</blockquote>

<p>Strictly speaking, we are not the issuer this time around (the GXDCH is) but since the Notarization API allows us to specify those identifiers, we will keep that responsibility nonetheless and have the choice here.</p>

<p>We are just about to receive the Gaia-X Credential and as such we don’t have the URL to it yet that we want to use in the identifiers, so the process can seem a bit unintuitive.
The solution is to prematurely specify the URL where we <em>intend</em> to put the Gaia-X Credential, in our example this will be <code class="language-plaintext highlighter-rouge">https://mydomain.com/.well-known/lrn.json</code>.
The link is not actually validated by the Notarization API as it only issues the Gaia-X Credential itself.
To adhere to the requirement of keeping identifiers unique, we can use a trick to attach arbitrary anchors to the URL in order to keep both identifiers different while still resolving to the same URL:</p>

<ul>
  <li>Verifiable Credential identifier: <code class="language-plaintext highlighter-rouge">https://mydomain.com/.well-known/lrn.json</code></li>
  <li>Credential subject identifier: <code class="language-plaintext highlighter-rouge">https://mydomain.com/.well-known/lrn.json#subject</code></li>
</ul>

<p>A corresponding request body to the Tagus release version of the Notarization API would look as follows.</p>

<p>Request URL:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>POST https://registrationnumber.notary.lab.gaia-x.eu/v1/registrationNumberVC?vcid=https://mydomain.com/.well-known/lrn.json#subject
</code></pre></div></div>

<p>Request Body:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"https://registry.lab.gaia-x.eu/v1-staging/api/trusted-shape-registry/v1/shapes/jsonld/participant"</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:legalRegistrationNumber"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/lrn.json"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"gx:vatID"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DE123456789"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Note: It is not mandatory to use the <code class="language-plaintext highlighter-rouge">/.well-known/</code> directory here.
In contrast to the DID document, web server, path and filename can be arbitrary here as long as we host the resulting Gaia-X Credential at this address later on.
This is true for all the Gaia-X Credentials that we will create in the following sections.</p>

<p>The Notarization API supports different types of Legal Registration Numbers, including VAT ID which our example uses.</p>

<p>In the response to this request we receive our first Gaia-X Credential from the Notarization API in JSON format.
Below is an example of how such a Gaia-X Credential will look like based on the request data above.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="s2">"https://www.w3.org/2018/credentials/v1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"https://w3id.org/security/suites/jws-2020/v1"</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="s2">"VerifiableCredential"</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/lrn.json"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"issuer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:registration.lab.gaia-x.eu:v1"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"issuanceDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-06-25T14:38:38.898Z"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"credentialSubject"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://registry.lab.gaia-x.eu/developmhttps://cloudandheat.com/gaia-x/x509_cert_chain.pement/api/trusted-shape-registry/v1/shapes/jsonld/trustframework#"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:legalRegistrationNumber"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/lrn.json#subject"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"gx:vatID"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DE123456789"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"gx:vatID-countryCode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DE"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"evidence"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"gx:evidenceURL"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://ec.europa.eu/taxation_customs/vies/services/checkVatService"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:executionDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-06-25T14:38:38.898Z"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:evidenceOf"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:vatID"</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"proof"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"JsonWebSignature2020"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"created"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-06-25T14:38:38.916Z"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"proofPurpose"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assertionMethod"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"verificationMethod"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:registration.lab.gaia-x.eu:v1#X509-JWK2020"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"jws"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;signature&gt;"</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>(the JWS signature field has been replaced by the placeholder <code class="language-plaintext highlighter-rouge">&lt;signature&gt;</code> for readability)</p>

<p>We will put this JSON file on our web server at the path we specified during the request, i.e., <code class="language-plaintext highlighter-rouge">mydomain.com/.well-known/lrn.json</code>.</p>

<p>The Gaia-X Credential that we received contains a DID reference to the DID document of the Gaia-X Notarization Service which in turn will reference a X.509 certificate chain of the Notarization Service that can be used to validate the signature of the Gaia-X Credential.
Refer to the <a href="#appendix">appendix section</a> at the bottom of this blog post for a Python code snippet for validating the signature.</p>

<p>In contrast to the figures above, the issuer is the GXDCH and the CSP itself is just the holder of this Gaia-X Credential:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/gx-credentials/gx-lrn-credential-creation-8af3137637d98afd4cadc287f8dd8663f5084fc3d3daa8c578e740cf70a839afb06e05f08347de83e378d83c4042316eac06f0d5fde907ec3c68fe15752e2ad6.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-lrn-credential-creation-8af3137637d98afd4cadc287f8dd8663f5084fc3d3daa8c578e740cf70a839afb06e05f08347de83e378d83c4042316eac06f0d5fde907ec3c68fe15752e2ad6.png" />
  </a>
</figure>

<p>Based on this LRN credential we can proceed with our first self-signed Gaia-X Credential next: the Participant.</p>

<h3 id="step-4-gaia-x-credential-for-participant">Step 4: Gaia-X Credential for Participant</h3>

<p>The <a href="https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/participant/">Participant in the Gaia-X Trust Framework</a> is described as:</p>

<blockquote>
  <p>[…] a Legal Person or Natural Person, which is identified, onboarded and has a Gaia-X Credential.</p>
</blockquote>

<p>In case of a Legal Person (our case), the Legal Registration Number is required which we just acquired the Gaia-X Credential for in the previous step.</p>

<p>Since the Participant Gaia-X Credential will be the first credential that we sign ourselves in this process, we will need three additional key assets that we prepared in earlier steps:</p>

<ol>
  <li>The <code class="language-plaintext highlighter-rouge">privkey.pem</code>, our private key for signing the credential.</li>
  <li>The <code class="language-plaintext highlighter-rouge">did:web:</code> reference pointing to our hosted DID document, which in turn points to our hosted certificate chain.</li>
  <li>The credential subject identifier of our LRN Gaia-X Credential to reference to.</li>
</ol>

<p>The LRN credential’s <code class="language-plaintext highlighter-rouge">credentialSubject.id</code> value will need to be specified within <code class="language-plaintext highlighter-rouge">credentialSubject.gx:legalRegistrationNumber.id</code> of the Participant Gaia-X Credential:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/gx-credentials/gx-participant-lrn-reference-80d6abdc827f6a211cbd3020536ef647ae43ca10dab9985f110e39c67d0a3b9ff55c86916404fcc258d54645c663d4fd04ac022750251aad2f67db15d9707384.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-participant-lrn-reference-80d6abdc827f6a211cbd3020536ef647ae43ca10dab9985f110e39c67d0a3b9ff55c86916404fcc258d54645c663d4fd04ac022750251aad2f67db15d9707384.png" />
  </a>
</figure>

<p>This time we are going to create and sign the Gaia-X Credential ourselves.
Here is how it could look like:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"https://www.w3.org/2018/credentials/v1"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"https://w3id.org/security/suites/jws-2020/v1"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"https://registry.lab.gaia-x.eu/v1-staging/api/trusted-shape-registry/v1/shapes/jsonld/trustframework#"</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"VerifiableCredential"</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/participant.json"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"issuer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:mydomain.com"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"issuanceDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-01-01T00:00:00.000000"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"credentialSubject"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/participant.json#subject"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:LegalParticipant"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"gx:legalName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"My Company Ltd."</span><span class="p">,</span><span class="w">
    </span><span class="nl">"gx:legalRegistrationNumber"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/lrn.json#subject"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"gx:headquarterAddress"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"gx:countrySubdivisionCode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DE-BE"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"gx:legalAddress"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"gx:countrySubdivisionCode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DE-BE"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Note that similar to the LRN Gaia-X Credential we are once again specifying a URL that does not exist yet for this credential’s identifiers: <code class="language-plaintext highlighter-rouge">https://mydomain.com/.well-known/participant.json</code>.
We will place this very credential there once we signed it.
Furthermore, we are using the same anchor method (<code class="language-plaintext highlighter-rouge">#subject</code>) to keep identifiers unique as already explained for the LRN credential earlier.</p>

<p>To sign the Gaia-X Credential we need to add a JSON Web Signature (JWS) to it.
Please refer to the appendix at the bottom of this blog post for an example Python implementation utilizing the <code class="language-plaintext highlighter-rouge">jwcrypto</code> library.
As a result, the structure shown above will be extended by a “proof” section containing the signature like this:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">  </span><span class="err">...</span><span class="w">
  </span><span class="nl">"proof"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"JsonWebSignature2020"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"proofPurpose"</span><span class="p">:</span><span class="w"> </span><span class="s2">"assertionMethod"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"verificationMethod"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:mydomain.com#JWK2020-RSA"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"jws"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;signature&gt;"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>To make the identifier references valid, we will place the signed JSON at <code class="language-plaintext highlighter-rouge">mydomain.com/.well-known/participant.json</code> on our web server.
Other Gaia-X Participants may now retrieve this Gaia-X Credential along with our DID document and its referenced X.509 certificate chain in order to validate the signature of our credential as illustrated in the figures of the introductory sections.</p>

<h3 id="step-5-gaia-x-credential-for-terms--conditions">Step 5: Gaia-X Credential for Terms &amp; Conditions</h3>

<p>The second Gaia-X Credential that we will sign ourselves will be the Gaia-X Terms &amp; Conditions which we pledge to adhere to as a participant in the Gaia-X Trust Framework.</p>

<p>The mandatory Terms &amp; Conditions text can be found at <code class="language-plaintext highlighter-rouge">https://registry.lab.gaia-x.eu/v1-staging/api/termsAndConditions</code> endpoint of GXDCH Registry Service.
A resulting credential JSON using example values may look like this:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"https://www.w3.org/2018/credentials/v1"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"https://w3id.org/security/suites/jws-2020/v1"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"https://registry.lab.gaia-x.eu/v1-staging/api/trusted-shape-registry/v1/shapes/jsonld/trustframework#"</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VerifiableCredential"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"issuanceDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-01-01T00:00:00.000000"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"credentialSubject"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:GaiaXTermsAndConditions"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"gx:termsAndConditions"</span><span class="p">:</span><span class="w"> </span><span class="s2">"The PARTICIPANT signing the Self-Description agrees as follows:</span><span class="se">\n</span><span class="s2">- to update its descriptions about any changes, be it technical, organizational, or legal - especially but not limited to contractual in regards to the indicated attributes present in the descriptions.</span><span class="se">\n\n</span><span class="s2">The keypair used to sign Verifiable Credentials will be revoked where Gaia-X Association becomes aware of any inaccurate statements in regards to the claims which result in a non-compliance with the Trust Framework and policy rules defined in the Policy Rules and Labelling Document (PRLD)."</span><span class="p">,</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/gx-terms-and-cs.json#subject"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"issuer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:mydomain.com"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/gx-terms-and-cs.json"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The structure and content of the credential is slightly different but the process is the same as for the Participant Gaia-X Credential.
In short:</p>

<ol>
  <li>Sign the JSON using the <code class="language-plaintext highlighter-rouge">privkey.pem</code>.</li>
  <li>Extend the JSON by a “proof” section containing the JSON Web Signature (JWS).</li>
  <li>Publish the resulting Gaia-X Credential as JSON at <code class="language-plaintext highlighter-rouge">mydomain.com/.well-known/gx-terms-and-cs.json</code>.</li>
</ol>

<p>Once again, other Gaia-X Participants may now retrieve this signed credential and validate its signature using our DID reference and the resulting public key.</p>

<h3 id="step-6-building-the-verifiable-presentation-for-the-compliance-api">Step 6: Building the Verifiable Presentation for the Compliance API</h3>

<p>Here is a recap of the assets we created so far:</p>

<ol>
  <li>Our public/private key pair, the X.509 certificate and DID document.</li>
  <li>A Gaia-X Credential attesting our Legal Registration Number (LRN), signed by the Gaia-X Notarization Service.</li>
  <li>A self-signed Gaia-X Credential describing our identity as Participant, referencing our LRN credential.</li>
  <li>A self-signed Gaia-X Credential for the Gaia-X Terms &amp; Conditions we pledge to adhere to.</li>
</ol>

<p>Using this minimal set of credentials we can now build a Verifiable Presentation for ourselves and submit it to the <a href="https://compliance.lab.gaia-x.eu/v1-staging/docs">Gaia-X Compliance API</a>.</p>

<p>The process is pretty straightforward and only requires us to assemble all desired Gaia-X Credentials in a Verifiable Presentation structure:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://www.w3.org/2018/credentials/v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VerifiablePresentation"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"verifiableCredential"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">LRN</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">Participant</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">Terms</span><span class="w"> </span><span class="err">&amp;</span><span class="w"> </span><span class="err">Conditions</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The JSON objects within the <code class="language-plaintext highlighter-rouge">verifiableCredential</code> list are the entire signed JSON structures (including the “proof” section) as individually created in the previous steps.
They are omitted and replaced by placeholders here for readability.</p>

<p>Please note that there is a mismatch between the Gaia-X official documentation and the implementation of the GXDCH Compliance Service for the Tagus release.
According to the <a href="https://gaia-x.gitlab.io/policy-rules-committee/compliance-document/Process/">Gaia-X specification</a>, the Compliance Service requires a <a href="https://www.w3.org/TR/vc-data-model/#dfn-verifiable-presentations">W3C Verifiable Presentation</a> as input.
A Verifiable Presentation is a set of Verifiable Credentials, whose authorship can be cryptographically verified, i.e., each Verifiable Presentation MUST contain at least one “proof” section.
In contrast to this requirement, the Gaia-X Compliance Service accepts Verifiable Presentations without a “proof” section, which is just a Presentation according to the <a href="https://www.w3.org/TR/vc-data-model/#presentations-0">W3C Verifiable Credentials Data Model v1.1</a>.
This mismatch was already <a href="https://gitlab.com/gaia-x/technical-committee/identity-credentials-and-access-management-working-group/icam/-/issues/72">reported</a> by the community.</p>

<p>We simply send the request body referenced above to <code class="language-plaintext highlighter-rouge">https://compliance.lab.gaia-x.eu/v1-staging/api/credential-offers</code> and as a response we receive yet another Gaia-X Credential, assumed that the Gaia-X Compliance Service can successfully validate the signature of each individual credential contained in the Verifiable Presentation.</p>

<p>This time, the received credential does not contain the whole input structure again, which would include the full JSON representation of all Gaia-X Credentials included in the Verifiable Presentation.
Instead, credentials are only referenced by their subject ID and a hash of their content as received by the Gaia-X Compliance Service:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="err">...</span><span class="w">
    </span><span class="nl">"credentialSubject"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/lrn.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:legalRegistrationNumber"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/gx-terms-and-cs.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:GaiaXTermsAndConditions"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/participant.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:LegalParticipant"</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"proof"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="err">...</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>(output truncated for readability)</p>

<p>This final Gaia-X Credential is the Gaia-X Compliance VC and attests the compliance of our Verifiable Presentation and its included credentials.
We can now share the Verifiable Presentation along with this Gaia-X Compliance VC to prove our Gaia-X compliance as a Gaia-X Legal Participant.</p>

<p>However, this Verifiable Presentation on its own is not very useful to describe any properties of the services we offer as a CSP since it only concerns our identity.
Therefore, we want to create another Verifiable Presentation next which focuses on another Gaia-X class: the <strong>Service Offering</strong>.
For this, we need to create a corresponding Gaia-X Credential which we can then combine with some of the existing ones into another Verifiable Presentation for submission to the Gaia-X Compliance API.</p>

<h3 id="step-7-gaia-x-credential-for-service-offering">Step 7: Gaia-X Credential for Service Offering</h3>

<p>First, we need to create the Gaia-X Credential for the Service Offering.
The <a href="https://docs.gaia-x.eu/policy-rules-committee/trust-framework/22.10/service/">Gaia-X Trust Framework</a> expects four mandatory attributes, which have to be attested by a Gaia-X Credential for Service Offerings:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">providedBy</code>: A resolvable link to the Participant Gaia-X Credential providing the service.</li>
  <li><code class="language-plaintext highlighter-rouge">termsAndConditions</code>: A resolvable link to the Terms and Conditions applying to that service.</li>
  <li><code class="language-plaintext highlighter-rouge">policy</code>: A list of policies expressed using a DSL (e.g., Rego or ODRL), inlcuding access control, throttling, usage, retention, etc.</li>
  <li><code class="language-plaintext highlighter-rouge">dataAccountExport</code>: A list of methods to export data from your user’s account out of the service.</li>
</ol>

<p>The attribute <code class="language-plaintext highlighter-rouge">providedBy</code> links to a Gaia-X Credential representing the CSP.
We already created it in step 4 as a Verifiable Credential for <code class="language-plaintext highlighter-rouge">LegalParticipant</code>.
To refer to this credential, the value of <code class="language-plaintext highlighter-rouge">providedBy.id</code> must be the id of the credential subject of the Gaia-X Credential for <code class="language-plaintext highlighter-rouge">LegalParticipant</code>.</p>

<p>Here is how the resulting Gaia-X Credential for a Service Offering could look like:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"https://www.w3.org/2018/credentials/v1"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"https://w3id.org/security/suites/jws-2020/v1"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"https://registry.lab.gaia-x.eu/development/api/trusted-shape-registry/v1/shapes/jsonld/trustframework#"</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VerifiableCredential"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/service-offering.json"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"issuer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"did:web:mydomain.com"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"issuanceDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-01-01T00:00:00.000000"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"credentialSubject"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:ServiceOffering"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/service-offering.json#subject"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"gx:providedBy"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/participant.json#subject"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"gx:termsAndConditions"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="nl">"gx:URL"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/tandc/"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"gx:hash"</span><span class="p">:</span><span class="w"> </span><span class="err">...</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"gx:policy"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="s2">"default: allow intent"</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"gx:dataAccountExport"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"gx:requestType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"API"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"gx:accessType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"digital"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"gx:formatType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"application/plain"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"proof"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="err">...</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Note that the link between the Service Offering Credential and the Participant Credential is established through the reference of the credential subject identifier, not the credential identifier.
See the <a href="#current-limitations-when-linking-between-gaia-x-credentials">corresponding appendix section</a> for further details.
Furthermore, as the Gaia-X Compliance Service (at the time of writing) does not resolve URL references to other credentials, we cannot simply link to the credentials we created and published in the previous steps.
As a result, any referenced Gaia-X Credentials (e.g. the Participant Credential referenced by the Service Offering’s <code class="language-plaintext highlighter-rouge">gx:providedBy</code>) must be included in the Verifiable Presentation in the next step again.</p>

<h3 id="step-8-building-another-verifiable-presentation-including-the-service-offering">Step 8: Building another Verifiable Presentation including the Service Offering</h3>

<p>Using the Gaia-X Credentials for the Service Offering and the minimal set of credentials for the CSP, we can now build a Verifiable Presentation for our service and submit it to the <a href="https://compliance.lab.gaia-x.eu/v1-staging/docs">Gaia-X Compliance API</a>.</p>

<p>As we already performed the same procedure for our first Verifiable Presentation in step 6, this process is pretty straightforward.
We just have to add the Gaia-X Credential for our Service Offering to the Verifiable Presentation from step 6:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"@context"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://www.w3.org/2018/credentials/v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VerifiablePresentation"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"verifiableCredential"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">LRN</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">Participant</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">Terms</span><span class="w"> </span><span class="err">&amp;</span><span class="w"> </span><span class="err">Conditions</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="err">//</span><span class="w"> </span><span class="err">signed</span><span class="w"> </span><span class="err">Service</span><span class="w"> </span><span class="err">Offering</span><span class="w"> </span><span class="err">credential</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>After submitting this Verifiable Presentation to the Gaia-X Compliance API, we receive a Verifiable Credential which attests the compliance of our Service Offering with Gaia-X:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="err">...</span><span class="w">
    </span><span class="nl">"credentialSubject"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/lrn.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:legalRegistrationNumber"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/gx-terms-and-cs.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:GaiaXTermsAndConditions"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/participant.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:LegalParticipant"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:compliance"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://mydomain.com/.well-known/service-offering.json"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"gx:integrity"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sha256-&lt;hash&gt;"</span><span class="p">,</span><span class="w">
            </span><span class="err">...</span><span class="w">
            </span><span class="nl">"gx:type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"gx:ServiceOffering"</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"proof"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="err">...</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>(output truncated for readability)</p>

<h4 id="note-about-credential-linking-and-verification-by-the-gxdch-compliance-service">Note about credential linking and verification by the GXDCH Compliance Service</h4>

<p>At this point you may start to wonder why the GXDCH Compliance Service is able to verify the compliance of our Service Offering, when the proof and issuer of the CSP’s Verifiable Credentials are effectively lost, as we pointed out at the end of step 7 (see also the <a href="#current-limitations-when-linking-between-gaia-x-credentials">corresponding appendix section</a>).
Upon further examination, the GXDCH Compliance Service does evaluate the proof of the enclosing CSP’s credential regardless, which can be tested by tampering with the proof.
You will receive a HTTP status code 409 (Conflict):</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"The signature of the document with ID ... cannot be validated, please check the document has not been tampered"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"error"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Conflict"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"statusCode"</span><span class="p">:</span><span class="w"> </span><span class="mi">409</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>This can be ascribed to the fact that the Compliance Service expects all Gaia-X Credentials to be part of the same Verifiable Presentation.
The Compliance Service does not actually resolve any URL references for credentials.
Instead, identifiers act as keys for a local lookup within the same Verifiable Presentation.
The Compliance Service looks for a Gaia-X Credential whose credential subject’s <code class="language-plaintext highlighter-rouge">id</code> matches with a given key and traverses back to its issuer and proof.
This is only possible because the full credential (including proof and issuer) of the referenced subject is always part of the Verifiable Presentation due to the requirement imposed by the Compliance Service.</p>

<p>This behavior seems to be a workaround and stands in contrast with the Linked Data principles of <a href="https://www.w3.org/TR/json-ld11/">JSON-LD</a>, which usually build links based on resolvable URLs.
There is an ongoing discussion to clarify if and/or why this behaviour is intended, see <a href="https://gitlab.com/gaia-x/lab/compliance/gx-compliance/-/issues/78">this issue discussion at Gaia-X</a>.</p>

<h3 id="automated-gaia-x-credential-generation-for-scs-infrastructures">Automated Gaia-X Credential generation for SCS infrastructures</h3>

<p>The Sovereign Cloud Stack (SCS) project is building tools to automate the process of Gaia-X Credential generation for SCS infrastructures, making most of the manual steps unnecessary.
There are two SCS tools that can help you automate most of the manual processes described in this blog post:</p>

<ol>
  <li><a href="https://github.com/SovereignCloudStack/scs-did-creator/">scs-did-creator</a></li>
  <li><a href="https://github.com/SovereignCloudStack/gx-credential-generator">gx-credential-generator</a></li>
</ol>

<p>The <strong>scs-did-creator</strong> helps with creating a DID document based on the desired key pairs and basically covers step 2 of the instructions above.</p>

<p>The <strong>gx-credential-generator</strong> implements Gaia-X Credential generation for the CSP identity as well as OpenStack-related service offerings and covers steps 3 through 8.
For the service offering, it includes auto-discovery for SCS infrastructures using the OpenStack API.
An extension to also cover the Kubernetes layer of SCS infrastructures is planned for the future.</p>

<h2 id="summary">Summary</h2>

<p>In this blog post we introduced the basic concepts of Gaia-X Credentials and Verifiable Presentations used by participants of the Gaia-X Trust Framework.
We presented the requirements and basic steps for getting started with creating Gaia-X Credentials for our identity as a CSP as well as our offered services.
Based on this foundation, a Verifiable Presentation was constructed in a step-by-step fashion consisting of an example set of credentials for submission to the Gaia-X Compliance Service.
At each step we made sure to point out the crucial details of properly linking and providing the required identity assets in compliance to the Gaia-X framework.
We then submitted the Verifiable Presentation about our identity to the Gaia-X Compliance Service and received our first Gaia-X Compliance VC attesting its compliance.
To expand on this, in the final steps we created an additional Gaia-X Credential for the Service Offering class to represent our services and built another Verifiable Presentation based on it.</p>

<p>At the end we briefly presented tools developed by the SCS project to automate Gaia-X Credential generation for SCS infrastructures, which cover most of the manual steps described in this blog post.</p>

<p>The created Gaia-X Credentials can later be registered in the <a href="https://docs.gaia-x.eu/technical-committee/architecture-document/22.10/federation_service/#federated-catalogue">Federated Catalogues of Gaia-X</a> to make them discoverable for consumers within the Gaia-X ecosystem.</p>

<h1 id="appendix">Appendix</h1>

<h2 id="current-limitations-when-linking-between-gaia-x-credentials">Current limitations when linking between Gaia-X Credentials</h2>

<p>There is a notable quirk about how Gaia-X links Gaia-X Credentials to each other, which deviates from the W3C Verifiable Credential standard and needs some explanation.
According to the <a href="https://docs.gaia-x.eu/technical-committee/identity-credential-access-management/22.10/credential_format/#verifiable-credential">Gaia-X Credential Format</a>, each Gaia-X Credential MUST have a unique <code class="language-plaintext highlighter-rouge">id</code> element which SHOULD be a resolvable URL.
According to the <a href="https://www.w3.org/TR/vc-data-model/#identifiers">W3C Verifiable Credential Data Model 1.1</a> the <code class="language-plaintext highlighter-rouge">id</code> element acts as an identifier for credentials.
It seems obvious to use the credential’s identifier as value of <code class="language-plaintext highlighter-rouge">providedBy</code> attribute.</p>

<p>However, the Gaia-X Compliance Service expects the <code class="language-plaintext highlighter-rouge">id</code> value of the nested <strong>credential subject</strong> instead of the top-level <code class="language-plaintext highlighter-rouge">id</code> value of the <strong>Verifiable Credential</strong> itself.
Taking the Service Offering Credential as an example, the difference can be visualized like this:</p>

<figure class="figure mx-auto d-block" style="width:100%">
  <a href="/website/assets/images/blog/gx-credentials/gx-participant-so-relation-f78db8e84025d25148d38dd7fa37a3bab79f40795a6d6e2824055bde7393d3c02515d3c6c3c73f52c124b6f74212fb50f7431b92574fb7da4cc162945b234d99.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/gx-credentials/gx-participant-so-relation-f78db8e84025d25148d38dd7fa37a3bab79f40795a6d6e2824055bde7393d3c02515d3c6c3c73f52c124b6f74212fb50f7431b92574fb7da4cc162945b234d99.png" />
  </a>
</figure>

<p>Credential subjects themselves have neither a digital signature nor an issuer.
Only the owning Verifiable Credential has these properties but is not reachable from the credential subject in the hierarchy when traversing the RDF graph, strictly speaking.
A verifier would not be able to properly validate authorship or recognize tampering of referenced claims, i.e., of a CSP in case of the <code class="language-plaintext highlighter-rouge">providedBy</code> of Service Offering Gaia-X Credentials.
This behaviour seems detrimental and was already requested to be clarified, see <a href="https://gitlab.com/gaia-x/lab/compliance/gx-compliance/-/issues/78">this issue discussion at Gaia-X</a>.</p>

<h2 id="python-code-for-signing-verifiable-credentials">Python code for signing Verifiable Credentials</h2>

<p>The following code snippet illustrates how to build a signed Verifiable Credential using the <code class="language-plaintext highlighter-rouge">jwcrypto</code> library and the assets introduced in this blog post.
The code is loosely based on <a href="https://gitlab.com/gaia-x/lab/workshops/gaia-x-101/-/blob/e0b01980eead64c0a20fec4643659b4c9d9f3331/utils.py">this example implementation from a Gaia-X workshop</a> that was published and licensed under the <a href="https://gitlab.com/gaia-x/lab/workshops/gaia-x-101/-/blob/e0b01980eead64c0a20fec4643659b4c9d9f3331/LICENSE">Eclipse Public License - v 2.0</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">json</span>
<span class="kn">from</span> <span class="n">hashlib</span> <span class="kn">import</span> <span class="n">sha256</span>
<span class="kn">from</span> <span class="n">jwcrypto</span> <span class="kn">import</span> <span class="n">jws</span><span class="p">,</span> <span class="n">jwk</span>
<span class="kn">from</span> <span class="n">jwcrypto.common</span> <span class="kn">import</span> <span class="n">json_encode</span>
<span class="kn">from</span> <span class="n">pyld</span> <span class="kn">import</span> <span class="n">jsonld</span>


<span class="k">def</span> <span class="nf">compact_token</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
    <span class="n">parts</span> <span class="o">=</span> <span class="n">token</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="sh">"</span><span class="s">..</span><span class="sh">"</span> <span class="o">+</span> <span class="n">parts</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">sign_credential</span><span class="p">(</span><span class="n">credential</span><span class="p">):</span>
    <span class="c1"># The private key used for signing
</span>    <span class="n">private_key</span> <span class="o">=</span> <span class="n">jwk</span><span class="p">.</span><span class="n">JWK</span><span class="p">.</span><span class="nf">from_pem</span><span class="p">(</span><span class="sh">"</span><span class="s">privkey.pem</span><span class="sh">"</span><span class="p">)</span>
    <span class="c1"># DID reference to the did.json
</span>    <span class="n">verification_method</span> <span class="o">=</span> <span class="sh">"</span><span class="s">did:web:mydomain.com#JWK2020-RSA</span><span class="sh">"</span>
    <span class="c1"># URDNA normalize
</span>    <span class="n">normalized</span> <span class="o">=</span> <span class="n">jsonld</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span>
        <span class="n">credential</span><span class="p">,</span> <span class="p">{</span><span class="sh">'</span><span class="s">algorithm</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">URDNA2015</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">format</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">application/n-quads</span><span class="sh">'</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="c1"># sha256 the RDF
</span>    <span class="n">normalized_hash</span> <span class="o">=</span> <span class="nf">sha256</span><span class="p">(</span><span class="n">normalized</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">))</span>
    <span class="c1"># Sign using JWS
</span>    <span class="n">jws_token</span> <span class="o">=</span> <span class="n">jws</span><span class="p">.</span><span class="nc">JWS</span><span class="p">(</span><span class="n">normalized_hash</span><span class="p">.</span><span class="nf">hexdigest</span><span class="p">())</span>
    <span class="n">jws_token</span><span class="p">.</span><span class="nf">add_signature</span><span class="p">(</span><span class="n">private_key</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span>
                            <span class="nf">json_encode</span><span class="p">(</span>
                                <span class="p">{</span><span class="sh">"</span><span class="s">alg</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">PS256</span><span class="sh">"</span><span class="p">,</span>
                                <span class="sh">"</span><span class="s">b64</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
                                <span class="sh">"</span><span class="s">crit</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">b64</span><span class="sh">"</span><span class="p">]}</span>
                            <span class="p">),</span>
                            <span class="nf">json_encode</span><span class="p">({</span><span class="sh">"</span><span class="s">kid</span><span class="sh">"</span><span class="p">:</span> <span class="n">private_key</span><span class="p">.</span><span class="nf">thumbprint</span><span class="p">()}))</span>
    <span class="n">signed</span> <span class="o">=</span> <span class="n">jws_token</span><span class="p">.</span><span class="nf">serialize</span><span class="p">(</span><span class="n">compact</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># Add the "proof" section to the credential
</span>    <span class="n">credential</span><span class="p">[</span><span class="sh">'</span><span class="s">proof</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">type</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">JsonWebSignature2020</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">proofPurpose</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assertionMethod</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">verificationMethod</span><span class="sh">"</span><span class="p">:</span> <span class="n">verification_method</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">jws</span><span class="sh">"</span><span class="p">:</span> <span class="nf">compact_token</span><span class="p">(</span><span class="n">signed</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">credential</span>
</code></pre></div></div>

<h2 id="python-code-for-verifying-signed-verifiable-credentials">Python code for verifying signed Verifiable Credentials</h2>

<p>The following code snippet illustrates how to validate the JSON Web Signature (JWS) of a given Verifiable Credential.
The code is loosely based on <a href="https://gitlab.com/gaia-x/lab/workshops/gaia-x-101/-/blob/e0b01980eead64c0a20fec4643659b4c9d9f3331/utils.py">this example implementation from a Gaia-X workshop</a> that was published and licensed under the <a href="https://gitlab.com/gaia-x/lab/workshops/gaia-x-101/-/blob/e0b01980eead64c0a20fec4643659b4c9d9f3331/LICENSE">Eclipse Public License - v 2.0</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">from</span> <span class="n">hashlib</span> <span class="kn">import</span> <span class="n">sha256</span>
<span class="kn">from</span> <span class="n">jwcrypto</span> <span class="kn">import</span> <span class="n">jwk</span><span class="p">,</span> <span class="n">jws</span>
<span class="kn">from</span> <span class="n">pyld</span> <span class="kn">import</span> <span class="n">jsonld</span>


<span class="k">def</span> <span class="nf">verify_credential</span><span class="p">(</span><span class="n">credential_json_str</span><span class="p">,</span> <span class="n">cert_url</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    credential_json_str : the signed Verifiable Credential as JSON string.

    cert_url : the URL to the signature verification certificate usually
    encoded as the x5u attribute of the issuer</span><span class="sh">'</span><span class="s">s did.json document.
    </span><span class="sh">"""</span>

    <span class="n">verifiable_credential</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">credential_json_str</span><span class="p">)</span>

    <span class="c1"># Retrieve the registry certificate which serves as the verification
</span>    <span class="c1"># public key (JWK) for the JWS later
</span>    <span class="n">reg_cert_response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">cert_url</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">reg_cert_response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nc">Exception</span><span class="p">(</span>
            <span class="sa">f</span><span class="sh">"</span><span class="s">Unable to retrieve verification certificate </span><span class="sh">"</span>
            <span class="sa">f</span><span class="sh">"</span><span class="s">from: </span><span class="si">{</span><span class="n">cert_url</span><span class="si">}</span><span class="sh">"</span>
        <span class="p">)</span>
    <span class="n">verification_cert_pem</span> <span class="o">=</span> <span class="n">reg_cert_response</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">UTF-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">verification_key</span> <span class="o">=</span> <span class="n">jwk</span><span class="p">.</span><span class="n">JWK</span><span class="p">.</span><span class="nf">from_pem</span><span class="p">(</span><span class="n">verification_cert_pem</span><span class="p">)</span>

    <span class="c1"># The proof object is part of the credential response, however
</span>    <span class="c1"># it resembles JWS data applicable to the response without the
</span>    <span class="c1"># proof object. Hence, we need to strip the proof object from
</span>    <span class="c1"># the response.
</span>    <span class="n">proof</span> <span class="o">=</span> <span class="n">verifiable_credential</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="sh">"</span><span class="s">proof</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># The remaining structure is the actual credential data that
</span>    <span class="c1"># JWS was created for. The signature was applied to its
</span>    <span class="c1"># normalized and hashed form, which we need to recreate here
</span>    <span class="c1"># in order to verify the signature.
</span>    <span class="c1"># See: https://w3c.github.io/vc-data-integrity/#how-it-works
</span>    <span class="n">normalized_credential</span> <span class="o">=</span> <span class="n">jsonld</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span>
        <span class="n">verifiable_credential</span><span class="p">,</span>
        <span class="p">{</span><span class="sh">'</span><span class="s">algorithm</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">URDNA2015</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">format</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">application/n-quads</span><span class="sh">'</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">hashed_credential</span> <span class="o">=</span> <span class="nf">sha256</span><span class="p">(</span><span class="n">normalized_credential</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">))</span>

    <span class="c1"># Instantiate a JWS object based on the jws attribute of the
</span>    <span class="c1"># proof object, which contains a base64 representation of the JWS.
</span>    <span class="n">received_jws_token</span> <span class="o">=</span> <span class="n">jws</span><span class="p">.</span><span class="nc">JWS</span><span class="p">()</span>
    <span class="n">received_jws_token</span><span class="p">.</span><span class="nf">deserialize</span><span class="p">(</span><span class="n">proof</span><span class="p">[</span><span class="sh">"</span><span class="s">jws</span><span class="sh">"</span><span class="p">])</span>

    <span class="c1"># Finally, use the verification key (Gaia X registry public cert)
</span>    <span class="c1"># and the hashed credential (which is the JWS' detached payload)
</span>    <span class="c1"># in conjunction with the JWS token to verify the credential.
</span>    <span class="c1"># This method will throw an exception if verification fails.
</span>    <span class="n">received_jws_token</span><span class="p">.</span><span class="nf">verify</span><span class="p">(</span>
        <span class="n">verification_key</span><span class="p">,</span>
        <span class="n">detached_payload</span><span class="o">=</span><span class="n">hashed_credential</span><span class="p">.</span><span class="nf">hexdigest</span><span class="p">()</span>
    <span class="p">)</span>
</code></pre></div></div>]]></content><author><name>[&quot;Markus Hentsch&quot;, &quot;Anja Strunk&quot;]</name></author><summary type="html"><![CDATA[This blog post will introduce the requirements and detailed technical process of creating and obtaining Verifiable Credentials (VC for short) for Gaia-X and using the Gaia-X Digital Clearing House (GXDCH) to assert compliance.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/default-card.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/default-card.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Ceph deployment with Rook</title><link href="https://sovereigncloudstack.github.io/website/tech/2024/10/14/ceph-rook/" rel="alternate" type="text/html" title="Ceph deployment with Rook" /><published>2024-10-14T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/tech/2024/10/14/ceph-rook</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/tech/2024/10/14/ceph-rook/"><![CDATA[<h2 id="ceph-deployment-with-rook">Ceph Deployment with Rook</h2>

<p>With the <a href="https://github.com/ceph/ceph-ansible/commit/a9d1ec844d24fcc3ddea7c030eff4cd6c414d23d">depreceation</a> of ceph-ansible, the SCS reference implementation now supports Ceph deployment with <a href="https://rook.io/docs/rook/latest-release/Getting-Started/intro/">Rook</a>, a <a href="https://www.cncf.io/announcements/2020/10/07/cloud-native-computing-foundation-announces-rook-graduation/">graduated-level cloud-native project</a>.</p>

<h2 id="osism-reference-implementation">OSISM Reference Implementation</h2>

<p>In OSISM, Rook is can be deployed using the officially recommended <a href="https://rook.io/docs/rook/latest-release/Helm-Charts/helm-charts/">Helm Charts</a>. Ansible is used to deploy the Helm charts for both the <a href="https://github.com/osism/ansible-collection-services/tree/main/roles/rook_operator">Rook Operator</a> and the <a href="https://github.com/osism/ansible-collection-services/tree/main/roles/rook">Rook Custom Resoruce Definitions</a>.</p>

<p>Rook deployment has also been integrated into the <a href="https://osism.tech/docs/guides/other-guides/testbed">OSISM testbed</a>. If you have a running testbed, you can login with <code class="language-plaintext highlighter-rouge">make login</code> and view the various OSISM commands related to rook by simply typing <code class="language-plaintext highlighter-rouge">osism apply</code> and grepping for ‘rook’:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dragon@testbed-manager:/opt/configuration/scripts/deploy$ osism apply | grep rook
| rook                                                             | rook           |
| rook-cleanup                                                     | rook           |
| rook-crd                                                         | rook           |
| rook-fetch-keys                                                  | rook           |
| rook-helm                                                        | rook           |
| rook-operator                                                    | rook           |
</code></pre></div></div>

<p>To install a minimal working rook you can use the helper script located in <code class="language-plaintext highlighter-rouge">/opt/configuration/scripts/deploy/100-rook-services.sh</code>, which automates the installation of <a href="https://docs.scs.community/docs/operating-scs/components/monitoring/docs/k3s/">k3s</a> and then runs the following commands:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>osism apply rook-operator
osism apply rook
osism apply rook-fetch-keys

# the role for the cephclient is informed which type of client should be installed. 
echo "cephclient_install_type: rook" &gt;&gt; /opt/configuration/environments/infrastructure/configuration.yml
osism apply cephclient
</code></pre></div></div>

<p>Note: the cephclient for OSISM is configured specifically for rook. It is a small role that ensures only the Rook client is setup.</p>

<h2 id="configuration">Configuration</h2>

<p>Rook can be configured by editing the variables for the Helm chart in the file <code class="language-plaintext highlighter-rouge">environments/rook/configuration.yml</code>. For more information on the various configuration options, see the <a href="https://docs.scs.community/docs/iaas/guides/configuration-guide/rook">SCS configration guide</a>.</p>

<p>The OSISM testbed provides the following default configuration at <code class="language-plaintext highlighter-rouge">/opt/configuration/environments/rook/config.yml</code> on the manager node:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
rook_network_public: "192.168.16.0/20"
rook_storage_devicefilter: "^sd[b-c]"
rook_storage_nodes:
  - name: "testbed-node-0"
  - name: "testbed-node-1"
  - name: "testbed-node-2"
## reduce resources to fit into testbed
rook_resources_cephfilesystem:
  limits:
    memory: "4Gi"
  requests:
    cpu: "500m"
    memory: "4Gi"
rook_resources_cephobjecstore:
  limits:
    memory: "2Gi"
  requests:
    cpu: "500m"
    memory: "1Gi"
## set to true to enable monitoring
# rook_monitoring_enabled: true
## set to true to enable cleanup
# rook_cleanup: true
</code></pre></div></div>]]></content><author><name>[&quot;Rafael te Boekhorst&quot;]</name></author><category term="tech" /><summary type="html"><![CDATA[Ceph Deployment with Rook]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/default-card.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/default-card.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">SCS-compatible IaaS: Example test and adapt</title><link href="https://sovereigncloudstack.github.io/website/2024/10/14/cert-adapt-example/" rel="alternate" type="text/html" title="SCS-compatible IaaS: Example test and adapt" /><published>2024-10-14T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/2024/10/14/cert-adapt-example</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/2024/10/14/cert-adapt-example/"><![CDATA[<h1 id="scs-compatible-iaas-example-test-and-adjust">SCS-compatible IaaS: Example test and adjust</h1>

<h2 id="run-the-tests">Run the tests</h2>

<p>Get the test suite by cloning <a href="https://github.com/SovereignCloudStack/standards/">the SCS standards repo</a>.
In order to run the tests, you need to have normal customer (tenant) access to the cloud or
container infrastructure that you want to test. (This is by design; we explicitly do not
require nor recommend admin level access for normal compliance testing.)</p>

<p>You can run the test suite from any machine that has a working <code class="language-plaintext highlighter-rouge">python3-openstacksdk</code> (for the
IaaS tests) or working <code class="language-plaintext highlighter-rouge">python3</code>, <code class="language-plaintext highlighter-rouge">kubectl</code> and <code class="language-plaintext highlighter-rouge">helm</code> (for the KaaS tests). Go to the
checked out tree into the <code class="language-plaintext highlighter-rouge">Tests/</code> directory to run tests. Check that the tooling works,
e.g. by issuing a command like <code class="language-plaintext highlighter-rouge">openstack --os-cloud=MYCLOUD catalog list</code> or
<code class="language-plaintext highlighter-rouge">KUBECONFIG=~/.kube/MYCLUSTER.yaml kubectl get nodes -o wide</code>.</p>

<p>Let’s do a run against a sample environment:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>garloff@framekurt<span class="o">(</span>//<span class="o">)</span>:/casa/src/SCS/standards/Tests <span class="o">[</span>1]<span class="nv">$ </span>./scs-compliance-check.py <span class="nt">-V</span> v4 <span class="nt">-s</span> CIAB <span class="nt">-a</span> <span class="nv">os_cloud</span><span class="o">=</span>ciab-test scs-compatible-iaas.yaml
INFO: module opc-v2022.11 missing checks or <span class="nb">test </span>cases
DEBUG: Fetching flavors from cloud <span class="s1">'ciab-test'</span>
DEBUG: Checking 28 flavor specs against 18 flavors
WARNING: Flavor <span class="s1">'SCS-4V-16'</span> found via name only, missing property <span class="s1">'scs:name-v2'</span>
ERROR: Flavor <span class="s1">'SCS-4V-16'</span> violating property constraints: scs:cpu-type: None should be <span class="s1">'shared-core'</span><span class="p">;</span> scs:name-v1: None should be <span class="s1">'SCS-4V:16'</span><span class="p">;</span> scs:name-v2: None should be <span class="s1">'SCS-4V-16'</span>
WARNING: Flavor <span class="s1">'SCS-8V-32'</span> found via name only, missing property <span class="s1">'scs:name-v2'</span>
ERROR: Flavor <span class="s1">'SCS-8V-32'</span> violating property constraints: scs:cpu-type: None should be <span class="s1">'shared-core'</span><span class="p">;</span> scs:name-v1: None should be <span class="s1">'SCS-8V:32'</span><span class="p">;</span> scs:name-v2: None should be <span class="s1">'SCS-8V-32'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-1V-4-10'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-2V-8-20'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-4V-16-50'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-8V-32-100'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-1V-2-5'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-2V-4-10'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-4V-8-20'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-8V-16-50'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-16V-32-100'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-1V-8-20'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-2V-16-50'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-4V-32-100'</span>
WARNING: Missing recommended flavor <span class="s1">'SCS-1L-1-5'</span>
DEBUG: Total critical / error / info: 0 / 2 / 0
DEBUG: Fetching image list from cloud <span class="s1">'ciab-test'</span>
DEBUG: Images present: Cirros 0.6.1, Cirros 0.6.2, Debian 12, Ubuntu 22.04 Minimal, openSUSE 15.6
DEBUG: Checking 6 image specs against 10 images
ERROR: Missing mandatory image <span class="s1">'Ubuntu 22.04'</span>
WARNING: Missing recommended image <span class="s1">'ubuntu-capi-image'</span>
DEBUG: Missing optional image <span class="s1">'Ubuntu 20.04'</span>
DEBUG: Missing optional image <span class="s1">'Debian 11'</span>
DEBUG: Missing optional image <span class="s1">'Debian 10'</span>
DEBUG: Total critical / error / warning: 0 / 1 / 1
<span class="k">********************************************************************************</span>
CIAB SCS-compatible IaaS v4 <span class="o">(</span>effective<span class="o">)</span>:
- main: FAIL <span class="o">(</span>3 passed, 2 failed<span class="o">)</span>
  - FAILED:
    - standard-flavors-check:
      <span class="o">&gt;</span> Must fulfill all requirements of https://docs.scs.community/standards/scs-0103-v1-standard-flavors
    - standard-images-check:
      <span class="o">&gt;</span> Must fulfill all requirements of https://docs.scs.community/standards/scs-0104-v1-standard-images
</code></pre></div></div>

<p>So we run the <em>SCS-compatible IaaS</em> tests defined in <code class="language-plaintext highlighter-rouge">scs-compatible-iaas.yaml</code> in version <code class="language-plaintext highlighter-rouge">v4</code>; without option <code class="language-plaintext highlighter-rouge">-V</code>,
all active versions would have been used, producing more output. We further define the cloud to be named <code class="language-plaintext highlighter-rouge">CIAB</code> (short for
Cloud-in-a-Box) in the report. And we set the parameter <code class="language-plaintext highlighter-rouge">os_cloud</code> to <code class="language-plaintext highlighter-rouge">ciab-test</code>. This references the
name of the cloud as configured in OpenStack <code class="language-plaintext highlighter-rouge">clouds.yaml</code> and <code class="language-plaintext highlighter-rouge">secure.yaml</code> which contain the configuration
and credentials to access the cloud as tenant user via the API (SDK or CLI).</p>

<p>Let’s have a look at the results:</p>

<ul>
  <li>We seem to have all 15 mandatory compute flavors, but two of them miss mandatory properties (<code class="language-plaintext highlighter-rouge">extra_specs</code>).
We also receive 13 warnings for not having recommended flavors, we can ignore them for now.</li>
  <li>On the images side, the mandatory image <code class="language-plaintext highlighter-rouge">Ubuntu 22.04</code> is not registered.</li>
  <li>The end result is that we passed three tests and failed to comply with two specs:</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="pi">-</span> <span class="na">FAILED</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">standard-flavors-check</span><span class="pi">:</span>
      <span class="pi">&gt;</span> <span class="err">Must</span> <span class="err">fulfill</span> <span class="err">all</span> <span class="err">requirements</span> <span class="err">of</span> <span class="err">https://docs.scs.community/standards/scs-0103-v1-standard-flavors</span>
    <span class="pi">-</span> <span class="na">standard-images-check</span><span class="pi">:</span>
      <span class="pi">&gt;</span> <span class="err">Must</span> <span class="err">fulfill</span> <span class="err">all</span> <span class="err">requirements</span> <span class="err">of</span> <span class="err">https://docs.scs.community/standards/scs-0104-v1-standard-images</span>
</code></pre></div></div>

<p>With option <code class="language-plaintext highlighter-rouge">-v</code>, we can make the test suite more verbose to e.g. see that we pass the flavor naming test,
the entropy test and the image metadata test.</p>

<h2 id="address-issues">Address issues</h2>

<p>To fix the failures, we will thus need to:</p>

<ul>
  <li>Add properties to the two flavors where they are missing.</li>
  <li>Register the <code class="language-plaintext highlighter-rouge">Ubuntu 22.04</code> image (with the appropriate metadata).</li>
</ul>

<p>Neither is difficult to do manually, but a more systematic and automated process is preferable.
For the first issue, there is a <a href="https://scs.community/de/tech/2024/08/20/flavor-extra-specs-compliance/">blog article on flavor metadata</a>.
For the image registration, the <a href="https://github.com/osism/openstack-image-manager">OpenStack Image Manager</a> can be used.</p>

<p>For adjusting the environment, we of course do need admin access to the cloud.
We use the tools referenced above:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>garloff@framekurt<span class="o">(</span>//<span class="o">)</span>:/casa/src/SCS/standards/Tests <span class="o">[</span>3]<span class="nv">$ OS_CLOUD</span><span class="o">=</span>ciab-admin ./iaas/flavor-naming/flavor-add-extra-specs.py <span class="nt">-a</span> apply
INFO: Flavor SCS-8V-32: SET scs:cpu-type<span class="o">=</span>shared-core
INFO: Flavor SCS-8V-32: SET scs:name-v1<span class="o">=</span>SCS-8V:32
INFO: Flavor SCS-8V-32: SET scs:name-v2<span class="o">=</span>SCS-8V-32
INFO: Flavor SCS-4V-16: SET scs:cpu-type<span class="o">=</span>shared-core
INFO: Flavor SCS-4V-16: SET scs:name-v1<span class="o">=</span>SCS-4V:16
INFO: Flavor SCS-4V-16: SET scs:name-v2<span class="o">=</span>SCS-4V-16
INFO: Processed 15 flavors, 6 changes
</code></pre></div></div>

<p>and as this is a OSISM-based SCS system, we can on the manager just run the image manager:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dragon@manager:~<span class="nv">$ </span>osism manage images <span class="nt">--cloud</span> admin <span class="nt">--filter</span> <span class="s2">"Ubuntu 22.04"</span>
2024-09-23 13:21:43 | INFO     | Processing image <span class="s1">'Ubuntu 22.04 (20240705)'</span>
2024-09-23 13:21:43 | INFO     | Tested URL https://swift.services.a.regiocloud.tech/swift/v1/AUTH_b182637428444b9aa302bb8d5a5a418c/openstack-images/ubuntu-22.04/20240705-ubuntu-22.04.qcow2: 200
2024-09-23 13:21:43 | INFO     | Importing image Ubuntu 22.04 <span class="o">(</span>20240705<span class="o">)</span>
2024-09-23 13:21:43 | INFO     | Importing from URL https://swift.services.a.regiocloud.tech/swift/v1/AUTH_b182637428444b9aa302bb8d5a5a418c/openstack-images/ubuntu-22.04/20240705-ubuntu-22.04.qcow2
2024-09-23 13:21:44 | INFO     | Waiting <span class="k">for </span>image to leave queued state...
2024-09-23 13:21:46 | INFO     | Waiting <span class="k">for </span>import to complete...
2024-09-23 13:21:56 | INFO     | Waiting <span class="k">for </span>import to complete...
2024-09-23 13:22:06 | INFO     | Waiting <span class="k">for </span>import to complete...
2024-09-23 13:22:16 | INFO     | Import of <span class="s1">'Ubuntu 22.04 (20240705)'</span> successfully completed, reloading images
2024-09-23 13:22:17 | INFO     | Checking parameters of <span class="s1">'Ubuntu 22.04 (20240705)'</span>
2024-09-23 13:22:17 | INFO     | Setting internal_version <span class="o">=</span> 20240705
2024-09-23 13:22:17 | INFO     | Setting image_original_user <span class="o">=</span> ubuntu
2024-09-23 13:22:17 | INFO     | Adding tag os:ubuntu
2024-09-23 13:22:17 | INFO     | Setting property architecture: x86_64
2024-09-23 13:22:17 | INFO     | Setting property hw_disk_bus: scsi
2024-09-23 13:22:17 | INFO     | Setting property hw_rng_model: virtio
2024-09-23 13:22:17 | INFO     | Setting property hw_scsi_model: virtio-scsi
2024-09-23 13:22:17 | INFO     | Setting property hw_watchdog_action: reset
2024-09-23 13:22:17 | INFO     | Setting property hypervisor_type: qemu
2024-09-23 13:22:17 | INFO     | Setting property os_distro: ubuntu
2024-09-23 13:22:18 | INFO     | Setting property os_version: 22.04
2024-09-23 13:22:18 | INFO     | Setting property replace_frequency: quarterly
2024-09-23 13:22:18 | INFO     | Setting property uuid_validity: last-3
2024-09-23 13:22:18 | INFO     | Setting property provided_until: none
2024-09-23 13:22:18 | INFO     | Setting property image_description: Ubuntu 22.04
2024-09-23 13:22:18 | INFO     | Setting property image_name: Ubuntu 22.04
2024-09-23 13:22:18 | INFO     | Setting property internal_version: 20240705
2024-09-23 13:22:18 | INFO     | Setting property image_original_user: ubuntu
2024-09-23 13:22:18 | INFO     | Setting property image_source: https://cloud-images.ubuntu.com/jammy/20240705/jammy-server-cloudimg-amd64.img
2024-09-23 13:22:18 | INFO     | Setting property image_build_date: 2024-07-05
2024-09-23 13:22:18 | INFO     | Checking status of <span class="s1">'Ubuntu 22.04 (20240705)'</span>
2024-09-23 13:22:18 | INFO     | Checking visibility of <span class="s1">'Ubuntu 22.04 (20240705)'</span>
2024-09-23 13:22:18 | INFO     | Setting visibility of <span class="s1">'Ubuntu 22.04 (20240705)'</span> to <span class="s1">'public'</span>
2024-09-23 13:22:19 | INFO     | Renaming Ubuntu 22.04 <span class="o">(</span>20240705<span class="o">)</span> to Ubuntu 22.04
2024-09-23 13:22:19 | INFO     | Processing image <span class="s1">'Ubuntu 22.04 Minimal (20240701)'</span>
dragon@manager:~<span class="err">$</span>
</code></pre></div></div>

<p>A description how <em>SCS-compatible IaaS</em> compliance can be achieved on environments that use different
OpenStack implementations is written up in a blog article
<a href="https://scs.community/de/2024/05/13/cost-of-making-an-openstack-cluster-scs-compliant/">Cost of making an OpenStack Cluster SCS compliant</a>.</p>

<h2 id="rerun-tests">Rerun tests</h2>

<p>We now succeed:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>garloff@framekurt<span class="o">(</span>//<span class="o">)</span>:/casa/src/SCS/standards/Tests <span class="o">[</span>130]<span class="nv">$ </span>./scs-compliance-check.py <span class="nt">-V</span> v4 <span class="nt">-s</span> CIAB <span class="nt">-a</span> <span class="nv">os_cloud</span><span class="o">=</span>ciab-test scs-compatible-iaas.yaml
INFO: module opc-v2022.11 missing checks or <span class="nb">test </span>cases
CIAB SCS-compatible IaaS v4 <span class="o">(</span>effective<span class="o">)</span>:
- main: PASS <span class="o">(</span>5 passed<span class="o">)</span>
</code></pre></div></div>

<p>If you don’t pass the tests yet, you’ll need further adjustments.</p>]]></content><author><name>[&quot;Kurt Garloff&quot;]</name></author><summary type="html"><![CDATA[SCS-compatible IaaS: Example test and adjust]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/default-card.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/default-card.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Contributing Upstream - how and why</title><link href="https://sovereigncloudstack.github.io/website/2024/09/19/upstream-contribution/" rel="alternate" type="text/html" title="Contributing Upstream - how and why" /><published>2024-09-19T00:00:00+00:00</published><updated>2025-09-30T08:38:05+00:00</updated><id>https://sovereigncloudstack.github.io/website/2024/09/19/upstream-contribution</id><content type="html" xml:base="https://sovereigncloudstack.github.io/website/2024/09/19/upstream-contribution/"><![CDATA[<h2 id="motivation">Motivation</h2>

<p>When deploying and operating an OpenStack installation, it is quite natural to discover bugs or features that
do not work as one would like them to work. This seems to be a natural entry point to contribute upstream,
either by creating a bug report, submitting a patch or discussing some design decision with the developers.</p>

<p>At least this is how it worked for me, then one thing led to another: Once you submit a patch, you’ll see CI
results that are triggered by your patch, likely some of these are not passing on the first attempt, so you
start looking into what these jobs are actually doing, how to find the logs they generate and how to interpret
them.</p>

<p>Contacting the people that operate the CI and discussing possible issues with it happens via IRC. Once you are
connected there, you also see what issues other people are having, try to understand what is happening or help
them if possible.</p>

<p>In the end this leads to a continous interplay of taking and giving, a community working together for a common
goal: Making the OpenStack project a healthy, stable and successful endeavour.</p>

<h2 id="qa-team---devstack-and-the-gate">QA Team - devstack and the gate</h2>

<blockquote>
  <p>DevStack is a series of extensible scripts used to quickly bring up a complete OpenStack environment based
on the latest versions of everything from git master. It is used interactively as a development environment
and as the basis for much of the OpenStack project’s functional testing.</p>
</blockquote>

<p>https://docs.openstack.org/devstack/latest/</p>

<p>One of the first OpenStack projects that I started contributing to was DevStack. Since for almost all
OpenStack repos their functional CI jobs are based on devstack and tempest, this is a crucial piece of code
for the whole project, so contributing to keep things in a healthy state is an important task.</p>

<p>The QA team has grown very small over the last five years or so, currently there are only three core reviewers
remaining that are regularly active. This is despite the team having been listed in the “help most wanted”
list for essentially since it exists
https://governance.openstack.org/tc/reference/upstream-investment-opportunities/2023/quality-assurance-developers.html.</p>

<p>Typical contributions include:</p>
<ul>
  <li>Triaging and answering bug reports</li>
  <li>Reviewing change requests</li>
  <li>Debugging CI failures and root-causing them</li>
  <li>Fixing issues that arise</li>
  <li>Ensuring support for new distro versions</li>
  <li>Responding to questions and comments in the IRC channel</li>
  <li>Taking part in the weekly meetings</li>
</ul>

<p>Without these, OpenStack development would soon grind to a halt, since lacking a working CI, no further
patches could be merged, no releases made and published, no bugs get fixed. So let us take a closer look at
how some of the above items work.</p>

<h2 id="launchpad-bug-tracking">Launchpad Bug tracking</h2>

<p>The <a href="https://launchpad.net">Launchpad</a> site is a complete code hosting and development site, similar to
GitHub. It is being developed and operated by <a href="https://canonical.com/">Canonical Ltd.</a>, the company behind the
Ubuntu Linux distribution. OpenStack only uses the bug tracking part of launchpad, which is available at
https://bugs.launchpad.net/.</p>

<p>There has also been an attempt from the OpenStack community to develop their own bug tracking software named
<a href="https://opendev.org/opendev/storyboard">Storyboard</a>, an instance of this is still running at
https://storyboard.openstack.org/. However this never became feature-complete compared to the Launchpad bug
tracker, so the migration to storyboard was stopped and a lot of project that had already switched to it have
since migrated back to Launchpad.</p>

<p>Users that discover a bug within OpenStack can report it at the URL that can be found in the documentation and
most of the time matches the project name, for example https://bugs.launchpad.net/devstack.</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/launchpad-devstack-index-5e76b38ddfa9e4ec17a4c78efa52687051458eb39161b59b680bb5b20f0c851996807453778166c3921441da46d09b103b770b2c58c38bb23e4eee1b03507a3c.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/launchpad-devstack-index-5e76b38ddfa9e4ec17a4c78efa52687051458eb39161b59b680bb5b20f0c851996807453778166c3921441da46d09b103b770b2c58c38bb23e4eee1b03507a3c.png" />
  </a>
</figure>

<p>The landing page shows a list of the open bug reports together with their priority and status, some statistics
on the number of open bugs, and finally a “Report a bug” button.</p>

<h2 id="gerrit-code-review">Gerrit Code Review</h2>

<p>The code review service <a href="https://www.gerritcodereview.com/">Gerrit</a> offers a web interface to allow an
efficient workflow for reviewing changes (the equivalent of what GitHub users know as pull requests). Take a
look at this devstack change for example:</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change-60a5c8a08060694730d43f2be0d1e714fb24f5a859f9bf319d9efd6f0f9d1efdfd8c5804199777224728c47b68caacdab3814d28028b71732c65453853579891.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change-60a5c8a08060694730d43f2be0d1e714fb24f5a859f9bf319d9efd6f0f9d1efdfd8c5804199777224728c47b68caacdab3814d28028b71732c65453853579891.png" />
  </a>
</figure>

<p>On the left of the upper half of the screen you can see all relevant details about the change, like the Owner,
the list of Reviewers and the current status of the review.</p>

<p>The box in the middle shows the commit messsage, which should contain all the information that the author of
the patch deems to be important for the reviewer to know and should also contain enough context so that future
developer can understand the meaning of the change when looking at it in the git history years into the
future.</p>

<p>On the right hand side of the upper half, changes are listed that are somehow related to the current patch.
The “Relation chain” lists other commits that were submitted together in a single branch. In GitHub those
would all be reviewed in one single piece as a pull request, in Gerrit however each commit is individually
tested and reviewed. Gerrit also allows to group reviews together by setting a common topic on them, these
reviews are shown in the “Same topic” list.</p>

<p>Below all this, the list of files that are touched by the change is shown. It includes some helpful hints,
like an indicator whether a file was newly added (“A”), modified (“M”) or deleted (“D”), and the amount of
lines changed (or number of bytes for non-text files).</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change2-81030a2166fe3646a51667d1421a6d81e0474e93bafe4c5a65041340b3447f736811ba571d2be6c6329215f877eb754673dbcb85f3636b0803ed93121a3c5849.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change2-81030a2166fe3646a51667d1421a6d81e0474e93bafe4c5a65041340b3447f736811ba571d2be6c6329215f877eb754673dbcb85f3636b0803ed93121a3c5849.png" />
  </a>
</figure>

<p>If we scroll further down, the log of events that affect this change is shown. This includes the initial
upload of the change for review, test results produced by the CI system (Zuul) and comments from reviewer,
including the votes that they left on the change.</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change-file-7946acf1da636c4ec58b014c0ab7fabb5f1185bbe5dff8e55c2c4598fa2f6c1c88492a3009cdf63e8ab9c8b5313c5346b7bd7b81bfd1b1e9f0f19bb5d9398d89.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change-file-7946acf1da636c4ec58b014c0ab7fabb5f1185bbe5dff8e55c2c4598fa2f6c1c88492a3009cdf63e8ab9c8b5313c5346b7bd7b81bfd1b1e9f0f19bb5d9398d89.png" />
  </a>
</figure>

<p>By clicking on a file name, one can take a look at what changed in this file, in this particular case for
lines were deleted. Clicking on a line allow to add some comment that will be shown attached to that line and
can thus be used to ask the reviewer for explanation in case something is unclear, suggest changes to the
commit, or possibly just leave comments for other reviewers.</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change-submit-3b6fab4851f46d1904173befd848b097e7daac7ec387b151fdb98529461da3113445a1f00feaaff95d52a682eda62d622748d2a2cd769cfcb68e4273388cf7f2.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/gerrit-devstack-change-submit-3b6fab4851f46d1904173befd848b097e7daac7ec387b151fdb98529461da3113445a1f00feaaff95d52a682eda62d622748d2a2cd769cfcb68e4273388cf7f2.png" />
  </a>
</figure>

<p>After going through all files, the “Reply” button on the main page will submit the review, adding all the
comments together with possibly a vote (-1 in this case since changes to the review are needed).</p>

<p>Most of this can be done by any interested contributor, the only requirement is to register an account, and
this is indeed a great option to start interacting with the community, seeing which topics are currently being
worked upon, learning about interesting parts of the code and helping to improve the quality of the software
that is being produced.</p>

<p>The only part where actual Core-Reviewer rights are needed is when it comes to actually approving a change to
be merged into the common code tree. This will usually require two different reviewer to leave a “+2” code
review on the patch and then to also submit a “Workflow+1” vote. At this point, the change will still not get
merged immediately, but instead the CI will perform another run of jobs, verifying all tests are still
passing, and only if these tests are successful, Zuul will instruct Gerrit to actually merge the change.</p>

<h2 id="zuul---stop-merging-broken-code">Zuul - Stop merging broken code</h2>

<blockquote>
  <p>Keep your builds evergreen by automatically merging changes only if they pass tests</p>
</blockquote>

<p>https://zuul-ci.org/</p>

<p>Initially testing the OpenStack project was using existing CI software like Jenkins to run its tests on
proposed changes. However a couple of limitations became apparent that in the end led to the development of a
new software: Zuul (see https://opensource.com/article/20/2/zuul for some overview of the history)</p>

<p>OpenDev’s instance of Zuul can be found at https://zuul.opendev.org/, it is not only serving OpenStack as one
of its tenants, but also the Zuul project itself as well as some other projects.</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/zuul-status-89b50dcadaf2a02cfe35b75fb8cf92af1cea5505e2cda10e209e0cb817af10f2ec5a9011545b57ab0805f65eca2290a98d3181a3d801b27f45013a22e355f548.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/zuul-status-89b50dcadaf2a02cfe35b75fb8cf92af1cea5505e2cda10e209e0cb817af10f2ec5a9011545b57ab0805f65eca2290a98d3181a3d801b27f45013a22e355f548.png" />
  </a>
</figure>

<p>The status page for each tenant shows the current state of the CI: Lists of currently running jobs, grouped by
pipeline, together with an estimation of how long it will take for these jobs to finish, based on historical
data from previous job executions.</p>

<figure class="figure mx-auto d-block" style="width:50%">
  <a href="/website/assets/images/blog/upstream-contribution/zuul-build-7eef05b03f1780d7dd23c9ae30f3f15185db0de7eaf60d17d56bf4a66814d3b5a796ee8e07545dc9432c6597f2d7a45c33214f88bef3f73bdfada0c3e1bf4dc0.png">
    <img class="figure-img w-100" src="/website/assets/images/blog/upstream-contribution/zuul-build-7eef05b03f1780d7dd23c9ae30f3f15185db0de7eaf60d17d56bf4a66814d3b5a796ee8e07545dc9432c6597f2d7a45c33214f88bef3f73bdfada0c3e1bf4dc0.png" />
  </a>
</figure>

<p>Looking at an individual build allows to see its status and to dig deeper into what went wrong in case there
was a failure. One can either follow the sequence of Ansible tasks that were executed in the Console view or
check the Logs that were collected.</p>

<h2 id="opendev---the-glue-that-holds-everything-together">OpenDev - the glue that holds everything together</h2>

<blockquote>
  <p>OpenDev is an evolution of the OpenStack Infrastructure project. The goal is to make OpenStack’s proven
software development tools available for projects outside of OpenStack. We believe that Free Software needs
Free tools and OpenDev provides one such set that has been proven to work at large and small scales of
development.</p>
</blockquote>

<p>https://docs.opendev.org/opendev/system-config/latest/project.html</p>

<p>The OpenDev team is operating all - or most of - the infrastructure that is being used in the development of
OpenStack. This includes:</p>

<ul>
  <li>The gitea server farm https://opendev.org/</li>
  <li>The gerrit code review server https://review.opendev.org/</li>
  <li>The Zuul CI system https://zuul.opendev.org/</li>
</ul>

<p>Add to that a lot of additional systems that help with development, monitoring and collaboration. Most of the
setup is being automated through the “Infrastructure as Code” concept, but since some of the tasks still
require administrator or root access to the servers, a good amount of experience with systems administration
is needed, as well as having earned the trust of the existing team through previous interactions.</p>

<p>Typical contributions include:</p>

<ul>
  <li>Reviewing change requests</li>
  <li>Debugging and fixing infrastructure issues</li>
  <li>Responding to questions and comments in the IRC channel</li>
  <li>Taking part in the weekly meetings</li>
</ul>

<h2 id="cirros---a-minimized-cloud-image">CirrOS - A minimized cloud image</h2>

<blockquote>
  <p>The CirrOS project provides linux disk and kernel/initramfs images. The images are well suited for testing
 as they are small and boot quickly.</p>
</blockquote>

<p>https://github.com/cirros-dev/cirros</p>

<p>The CirrOS project was developed by Scott Moser in order to have a small cloud image for testing purposes,
which allows to verify some basic functionality while consuming only a minimal amount of resources. This
makes tests work much faster than they would be when using a standard cloud image as provided by the usual
distros like Debian or Ubuntu. It also allows the CI to run multiple tests in parallel without hitting
resource limits on the testing node.</p>

<p>From time to time updates to the image are necessary, be it either using a newer kernel or an updated
software stack - the collection curated by <a href="https://buildroot.org/">the buildroot project</a>
is being used here - or adding new features or bugfixes.</p>

<h2 id="neutron-dynamic-routing---ipv6-connectivity-for-neutron">neutron-dynamic-routing - IPv6 connectivity for Neutron</h2>

<p>The neutron-dynamic-routing project is a small plugin for Neutron that provides the capability to announce
reachability information from OpenStack’s virtual networking to the outside world. One particularly important
application of this is to provide IPv6 connectivity with globally reachable addresses to Neutron tenant
networks. This has been documented in a detailed guide
<a href="https://docs.openstack.org/neutron-dynamic-routing/latest/install/usecase-ipv6.html">here</a>.</p>

<p>Due to lack of contributors the project was close to getting abandoned some years ago. But then two
contributors from operators stepped up to keep the project alive: Tobias Urdin from Binero and myself. In the
last months there has also been some renewed interest from other Neutron contributors and so the project can
be considered to be in a healthy state again for now.</p>

<h2 id="kolla---automated-openstack-deployments">kolla - Automated OpenStack deployments</h2>

<blockquote>
  <p>Kolla’s mission is to provide production-ready containers and deployment tools for operating OpenStack clouds.</p>
</blockquote>

<p>https://docs.openstack.org/kolla/latest/</p>

<p>Kolla is the basis of the OpenStack deployments provided by OSISM. The development follows an “upstream first”
policy whereever possible. So every new feature gets implemented in the upstream environment, ensuring
compatibility with the current state and thorough testing in the upstream CI, as well as receiving early
feedback from other Kolla developers.  Larger features usually get discussed with the community even before
work on the implementation starts. A good opportunity for this is at the PTG (Projects Team Gathering), which
is happening at the beginning of each 6 month development cycle for OpenStack, and which allows to discuss
ideas, design choices and possible options in a focused, concentrated enviroment where all interested parties
can participate.</p>

<p>The kolla project is using a large set of CI jobs to ensure that all features are working as expected and
to prevent changes from introducing regressions. These jobs cover a lot of different deployment scenarios,
each of them getting executed for all supported distributions - Debian, Rocky Linux and Ubuntu.</p>

<p>Typical contributions include:</p>

<ul>
  <li>Reviewing change requests</li>
  <li>Debugging and fixing CI issues</li>
  <li>Responding to questions and comments in the IRC channel</li>
  <li>Taking part in the weekly meetings</li>
</ul>

<h2 id="release-team---ensuring-quality-and-stability">Release Team - Ensuring quality and stability</h2>

<blockquote>
  <p>OpenStack is developed and released around 6-month cycles. After the initial release, additional stable
point releases will be released in each release series.</p>
</blockquote>

<p>https://releases.openstack.org/</p>

<p>The release team is responsible for overseeing the OpenStack release process. This includes verifying
the correctness of releases that are being made for individual deliverables, keeping the infrastructure
that creates these releases in good shape, and coordinating milestones and deadlines across the wider
OpenStack community.</p>

<p>The team is currently very small, not by design, but due to lack of contributors. So being active here
has an especially large impact on the healthiness of the whole project. There is some documentation
about <a href="https://releases.openstack.org/reference/join_release_team.html">joining the release team</a>, which
describes how interested contributors might start helping out by reviewing release patches.</p>

<p>Reviewing release patches is also the major recurring contribution, particular care is needed in
checking that the data are correct and that the reports generated by the CI do not show any possible
issues. From time to time, mostly around the major milestones and the final release, the team also
generates release patches themselves in order to help the other teams by making their part of the
job easier, as they’ll just have to verify that the generated patches are correct.</p>

<h2 id="technical-committee---leadership-and-firefighting">Technical Committee - Leadership and firefighting</h2>

<blockquote>
  <p>The OpenStack Technical Committee is the governing body of the OpenStack open source project. It is an
elected group that represents the contributors to the project, and has oversight on all technical matters.
This includes developers, operators and end users of the software.</p>
</blockquote>

<p>https://governance.openstack.org/tc/</p>

<p>The Technical Committee is the central technical governance body overseeing the while OpenStack project.
It is responsible for deciding upon the guidelines and policies that ensure that all services can work
together in a stable and verified manner. Most actions are getting discussed in the weekly meetings,
with longer term strategic planning also happening at the
[Project Team Gatherings (PTG)] (https://openinfra.dev/ptg/).</p>]]></content><author><name>[&quot;Dr. Jens Harbott&quot;]</name></author><summary type="html"><![CDATA[Motivation]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://sovereigncloudstack.github.io/website/default-card.jpg" /><media:content medium="image" url="https://sovereigncloudstack.github.io/website/default-card.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>